{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/croco22/CapstoneProjectTDS/blob/dev/notebooks/Huggingface_QA_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2: Evaluate Dataset"
      ],
      "metadata": {
        "id": "08r_8_xsdHfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install word2number\n",
        "\n",
        "import json\n",
        "import time\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import requests\n",
        "from word2number import w2n\n",
        "import re\n",
        "\n",
        "# API setup\n",
        "key = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=key)\n",
        "ai_model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "\n",
        "# Read dataset file\n",
        "url = 'https://raw.githubusercontent.com/croco22/CapstoneProjectTDS/refs/heads/main/qa_dataset.json'\n",
        "response = requests.get(url)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    data = response.json()\n",
        "    print(\"Retrieved file: qa_dataset.json\")\n",
        "else:\n",
        "    print(\"Error while parsing a file: \", response.status_code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgaZ4x_pZ2JI",
        "outputId": "e9ac4705-4a7b-4570-cb88-e8db5853c8a8"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: word2number in /usr/local/lib/python3.10/dist-packages (1.1)\n",
            "Retrieved file: qa_dataset.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_numbers_in_text(text):\n",
        "    # Regular expression to find number words contained in questionnaires\n",
        "    pattern = r'(two thousand|two hundred one|two hundred|fifty-one|thirty-one|twenty-one|sixteen|fifteen|eleven|thirty|twenty|fifty|forty|sixty|ten|five|six|one)'\n",
        "    # Interesting finding: Regex only works if longer words are in order before shorter that contain similar parts, e.g. fifty-one has to be in front of fifty to work as intended\n",
        "\n",
        "    def convert(match):\n",
        "        word = match.group(0)\n",
        "        try:\n",
        "            # Convert the word to number\n",
        "            return str(w2n.word_to_num(word))\n",
        "        except ValueError:\n",
        "            return word\n",
        "\n",
        "    # Replace all number words in the text with their integer equivalents\n",
        "    converted_text = re.sub(pattern, convert, text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Now convert ranges like 'twenty to thirty' into '20-30'\n",
        "    converted_text = re.sub(r'(\\d+)\\s*(to|and)\\s*(\\d+)', r'\\1-\\3', converted_text)\n",
        "\n",
        "    # Replace text\n",
        "    # Todo: Dafür noch ne bessere Lösung finden, das ist eig nur n Beispiel und geht auch bei ähnlichen Sätzen nicht\n",
        "    converted_text = converted_text.replace('more than 2000', 'larger than 2000')\n",
        "    converted_text = converted_text.replace('More than 2000', 'Larger than 2000')\n",
        "\n",
        "    return converted_text\n",
        "\n",
        "\n",
        "def is_exact_or_phrase_match(option, text):\n",
        "    # Escape the option to handle special characters\n",
        "    escaped_option = re.escape(option.strip())\n",
        "\n",
        "    # Pattern to match the option as a full word or part of a phrase\n",
        "    pattern = rf'\\b(?:\\w+\\s+)*{escaped_option}(?:\\s+\\w+)*\\b'\n",
        "\n",
        "    # Search for the pattern in the text (case-insensitive)\n",
        "    return re.search(pattern, text, re.IGNORECASE) is not None"
      ],
      "metadata": {
        "id": "z6wtn_c2jV6d"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate different models"
      ],
      "metadata": {
        "id": "DqGRIsmijWdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "qa_pipeline1 = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")"
      ],
      "metadata": {
        "id": "uIvrly2acd5D",
        "outputId": "8f9ce376-c01b-46f6-ca2c-9ff5066af8f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_pipeline2 = pipeline(\"question-answering\", model='distilbert-base-cased-distilled-squad')"
      ],
      "metadata": {
        "id": "hzzRZehgNovH",
        "outputId": "ed48b5cd-f666-40a4-920f-1db0828652a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_pipeline3 = pipeline(\"question-answering\", model='google-bert/bert-large-uncased-whole-word-masking-finetuned-squad')"
      ],
      "metadata": {
        "id": "1zCx0azeQNr1",
        "outputId": "483b7daf-3fb0-4d7a-8fe5-048266d0cbc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google-bert/bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_answers(data):\n",
        "    \"\"\"\n",
        "    Predict the answer for each option in the JSON data.\n",
        "    Printing only incorrectly predicted answers.\n",
        "    \"\"\"\n",
        "    print(\"[INFO] Printing only incorrectly predicted answers.\")\n",
        "    correct_count = 0\n",
        "    total_count = 0\n",
        "\n",
        "    for item in data:\n",
        "        predictions = list()\n",
        "\n",
        "        # Convert numbers contained in the text to actual integer values\n",
        "        converted_text = convert_numbers_in_text(item['answer_text'])\n",
        "\n",
        "        for option in item['possible_answers']:\n",
        "            # Check for exact match or part of a phrase\n",
        "            # Todo: Problem: Da der Loop zuerst für unsatisfied durchlaufen wird, wird diesem 95% zugewiesen,\n",
        "            # erst danach wird very unsatisfied ebenfalls 95% zugewiesen --> falsche Zuordnung\n",
        "            exact_match = is_exact_or_phrase_match(option, converted_text)\n",
        "            if exact_match:\n",
        "                predictions.append((option, 0.95)) # 95 % sure its the correct answer\n",
        "            else:\n",
        "                # Hier den Namen der Pipeline eingeben, die man testen will:\n",
        "                result = qa_pipeline1(question=item['question'], context=f\"{converted_text} {option}\")\n",
        "                predictions.append((option, result['score']))\n",
        "\n",
        "        predicted_option, confidence = max(predictions, key=lambda x: x[1])\n",
        "\n",
        "        if predicted_option == item['intended_answer']:\n",
        "            correct_count += 1\n",
        "        else:\n",
        "            print(f\"Text: {item['answer_text']}\")\n",
        "            print(f\"Correct: {item['intended_answer']}, Predicted: {predicted_option}, Confidence: {round(confidence, 4)} \\n\")\n",
        "        total_count += 1\n",
        "\n",
        "    accuracy = correct_count / total_count if total_count > 0 else 0\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "5tBOxf67w_ya"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = predict_answers(data)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f} %\")"
      ],
      "metadata": {
        "id": "MF3PQE8c4Ytn",
        "outputId": "ca83fd60-4bde-47c0-cba5-52b2b87eeddb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Printing only incorrectly predicted answers.\n",
            "Text: Nope, I'd rather not give consent for data processing, thanks.\n",
            "Correct: No, Predicted: Yes, Confidence: 0.0 \n",
            "\n",
            "Text: Oh yeah, I definitely work with wholesalers and distributors, they're a big part of my business.\n",
            "Correct: Wholesaler, Distributor, Predicted: Consultant, Planner, Architect, Confidence: 0.0 \n",
            "\n",
            "Text: Absolutely, my customer group consists of wholesalers and distributors – that's the heart of my operations.\n",
            "Correct: Wholesaler, Distributor, Predicted: End User, Confidence: 0.117 \n",
            "\n",
            "Text: Oh, the customer group?  That'd be consultants, planners, and architects, mostly.\n",
            "Correct: Consultant, Planner, Architect, Predicted: Wholesaler, Distributor, Confidence: 0.2673 \n",
            "\n",
            "Text: In terms of client base, we're focused on architects, planners, and consultants for this particular initiative.\n",
            "Correct: Consultant, Planner, Architect, Predicted: Wholesaler, Distributor, Confidence: 0.0 \n",
            "\n",
            "Text: Nope, I'd rather not be bombarded with marketing stuff in my inbox.\n",
            "Correct: No, Predicted: Yes, Confidence: 0.0371 \n",
            "\n",
            "Text: I work in aerospace – it's quite exciting, you know.\n",
            "Correct: Aerospace, Predicted: Government, Confidence: 0.9613 \n",
            "\n",
            "Text: The industry I'm currently operating within is defense.\n",
            "Correct: Defense, Predicted: Public Safety / Law Enforcement, Confidence: 0.9535 \n",
            "\n",
            "Text: Oh, I'm knee-deep in the world of Network Operators and Infrastructure, that's my gig!\n",
            "Correct: Network Operators & Infrastructure, Predicted: Government, Confidence: 0.8717 \n",
            "\n",
            "Text: Oh, I'm knee-deep in the world of public safety and law enforcement, that's my gig!\n",
            "Correct: Public Safety / Law Enforcement, Predicted: Automotive, Confidence: 0.6151 \n",
            "\n",
            "Text: I work in the public safety/law enforcement industry, it's a pretty demanding but rewarding field.\n",
            "Correct: Public Safety / Law Enforcement, Predicted: Physical Security, Confidence: 0.4966 \n",
            "\n",
            "Text: Yeah, I'm involved with public safety and law enforcement; it keeps things interesting, let me tell you!\n",
            "Correct: Public Safety / Law Enforcement, Predicted: Aerospace, Confidence: 0.8898 \n",
            "\n",
            "Text: Public safety and law enforcement is the area I operate within, if that's what you're asking.\n",
            "Correct: Public Safety / Law Enforcement, Predicted: Automotive, Confidence: 0.9176 \n",
            "\n",
            "Text: So, the short answer is, I'm in the public safety/law enforcement industry; it's a wild ride.\n",
            "Correct: Public Safety / Law Enforcement, Predicted: Network Operators & Infrastructure, Confidence: 0.4461 \n",
            "\n",
            "Text: The headcount?  Oh, it's well over 2000;  we're talking a substantial organization here.\n",
            "Correct: larger than 2000, Predicted: 201-2000, Confidence: 0.1209 \n",
            "\n",
            "Text: Yeah, we're a pretty massive company; our employee count is definitely above the 2000 mark, for sure.\n",
            "Correct: larger than 2000, Predicted: 1-10, Confidence: 0.4632 \n",
            "\n",
            "Text: I'd say I'm a returning customer, actually.  Been using your app for ages.\n",
            "Correct: Existing customer, Predicted: Partner, Confidence: 0.0052 \n",
            "\n",
            "Text: We're partners in this, you know.\n",
            "Correct: Partner, Predicted: New customer, Confidence: 0.0002 \n",
            "\n",
            "Text: Ugh, I'm very unsatisfied, to be honest.  The whole experience was a major letdown.\n",
            "Correct: Very unsatisfied, Predicted: Unsatisfied, Confidence: 0.95 \n",
            "\n",
            "Text: Honestly?  I'm very unsatisfied with the service I received.  It was a real disappointment.\n",
            "Correct: Very unsatisfied, Predicted: Unsatisfied, Confidence: 0.95 \n",
            "\n",
            "Text: Let's just say I'm very unsatisfied and I wouldn't recommend this app to my worst enemy.\n",
            "Correct: Very unsatisfied, Predicted: Unsatisfied, Confidence: 0.95 \n",
            "\n",
            "Text: Yeah, no, I'm very unsatisfied.  It was terrible, absolutely terrible.\n",
            "Correct: Very unsatisfied, Predicted: Unsatisfied, Confidence: 0.95 \n",
            "\n",
            "Text: I'm very unsatisfied, and frankly, I'm pretty furious about the whole thing.\n",
            "Correct: Very unsatisfied, Predicted: Unsatisfied, Confidence: 0.95 \n",
            "\n",
            "Accuracy: 92.33 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interesting Findings"
      ],
      "metadata": {
        "id": "tbWdbONKjb0L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Prediction of names very bad, because no deeper meaning --> fixed by checking for exact matches\n",
        "  * Maybe implement name interpreter later?\n",
        "*   Numerical values (size of company) prediction very bad\n",
        "\n",
        "* QA Pipelines\n",
        "  * Pipeline 2 und 3 haben nur eine accuracy von ungefähr 60 %\n",
        "\n"
      ],
      "metadata": {
        "id": "bZ_eWHUHggq1"
      }
    }
  ]
}