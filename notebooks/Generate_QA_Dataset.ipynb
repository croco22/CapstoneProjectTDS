{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/croco22/CapstoneProjectTDS/blob/main/notebooks/Generate_QA_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1: Generate Q&A Dataset"
      ],
      "metadata": {
        "id": "08r_8_xsdHfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import time\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import requests\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Create userdata folder in Colab environment\n",
        "!mkdir userdata\n",
        "\n",
        "# API setup\n",
        "key = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=key)\n",
        "ai_model = genai.GenerativeModel('gemini-1.5-flash')"
      ],
      "metadata": {
        "id": "jgaZ4x_pZ2JI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define modules to process different types of data"
      ],
      "metadata": {
        "id": "yvndzq1kaIs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_question(data):\n",
        "    \"\"\"\n",
        "    Generate spoken answers for the passed question in the JSON data.\n",
        "    A distinction is made between the different types of questions.\n",
        "    \"\"\"\n",
        "    type_handlers = {\n",
        "        \"SINGLE_SELECT\": handle_single_select,\n",
        "        \"MULTI_SELECT\": handle_multi_select,\n",
        "        \"TEXT\": handle_text,\n",
        "        \"DATE\": handle_date,\n",
        "        \"NUMBER\": handle_number,\n",
        "    }\n",
        "\n",
        "    data_type = data.get('type')\n",
        "    handler = type_handlers.get(data_type)\n",
        "\n",
        "    if handler:\n",
        "        return handler(data)\n",
        "    else:\n",
        "        exit(f\"Unhandled data type: {data_type}\")"
      ],
      "metadata": {
        "id": "DNRhF_GnXzGh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_single_select(data):\n",
        "    \"\"\"\n",
        "    Example output:\n",
        "    [{\"Yes, I am ...\": \"ee0437c0-6335-4b88-8bc5-d4eb8e2c68bf\"},\n",
        "    {\"Yes, blabla ...\": \"ee0437c0-6335-4b88-8bc5-d4eb8e2c68bf\"},\n",
        "    ...,\n",
        "    {\"No, I don't ...\": \"d357ab84-929f-440a-b9ad-42ff36402a53\"},\n",
        "    {\"Not agreed ...\": \"d357ab84-929f-440a-b9ad-42ff36402a53\"},\n",
        "    ...]\n",
        "    \"\"\"\n",
        "    answers = list()\n",
        "    for option in data['options']:\n",
        "        response_text = generate_single_answers(item['question'], option['option'])\n",
        "        texts_array = [answer.strip() for answer in response_text.split(\"§\")]\n",
        "\n",
        "        for text in texts_array:\n",
        "          answers.append({\n",
        "              text: option['id']\n",
        "          })\n",
        "\n",
        "        time.sleep(3) # Required in the free version to avoid exceeding API limits\n",
        "    return answers\n",
        "\n",
        "def handle_multi_select(data):\n",
        "    # Todo\n",
        "    pass\n",
        "\n",
        "def handle_text(data):\n",
        "    # Todo\n",
        "    pass\n",
        "\n",
        "def handle_date(data):\n",
        "    # Todo\n",
        "    pass\n",
        "\n",
        "def handle_number(data):\n",
        "    # Todo\n",
        "    pass"
      ],
      "metadata": {
        "id": "l76F8RJuaBQM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define module to generate text via API including AI prompts"
      ],
      "metadata": {
        "id": "A7bEJzqMavni"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xQdppMZmZv4W"
      },
      "outputs": [],
      "source": [
        "def generate_single_answers(question, option):\n",
        "    \"\"\"\n",
        "    API call to generate spoken answers for each option.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    You are the user of an app and you are responding in a spoken style to the following question.\n",
        "    You like to talk so you don't just say yes or no but rather answer with a whole sentence.\n",
        "    Question: \"{question}\"\n",
        "    Your answer should contain following content (e.g. if the content of the answer is yes, you convey this in your response):\n",
        "    Content of the answer: \"{option}\"\n",
        "    The responses should be in the following format and be kind of random so that each answer is in a different style.\n",
        "    Generate 5 answers that are split by a § sign and contain only text.\n",
        "    answer1§answer2§...§answer5\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = ai_model.generate_content(prompt)\n",
        "        return response.text.strip()\n",
        "    except Exception as e:\n",
        "        exit(\"Error during API call: \", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run defined modules for each question provided and save to a JSON-file"
      ],
      "metadata": {
        "id": "TJ-E8toBbBs4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_random_timestamp():\n",
        "    \"\"\"\n",
        "    Generate random timestamp within the last 30 days in the format '%Y%m%d_%H%M%S'.\n",
        "    \"\"\"\n",
        "    start_date = datetime.now() - timedelta(days=30)\n",
        "    random_seconds = random.randint(0, 30 * 24 * 60 * 60)\n",
        "    random_date = start_date + timedelta(seconds=random_seconds)\n",
        "    return random_date.strftime('%Y%m%d_%H%M%S')"
      ],
      "metadata": {
        "id": "ZABYLjJCdCF7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Close to real-word application"
      ],
      "metadata": {
        "id": "OEop2y31o6tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For each questionnaire (named 1-5)\n",
        "for questionnaire in range(1, 6):\n",
        "    url = f'https://raw.githubusercontent.com/croco22/CapstoneProjectTDS/refs/heads/main/questionnaires/questionnaire{questionnaire}.json'\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        print(f\"Retrieved file: questionnaire{questionnaire}.json\")\n",
        "    else:\n",
        "        print(\"Error while parsing a file: \", response.status_code)\n",
        "\n",
        "    # Generate a set of possible answers including the option id\n",
        "    answers_for_questions = list()\n",
        "    for item in data:\n",
        "        if item['type'] != 'SINGLE_SELECT': # Todo: Remove\n",
        "            answers_for_questions.append({})\n",
        "            continue\n",
        "        answers_for_questions.append({\n",
        "            item['id']: process_question(item)\n",
        "        })\n",
        "        print(f\"Generated answers for question '{item['question']}'.\")\n",
        "\n",
        "    # Generate 5 answer sheets\n",
        "    for sheet in range(1, 6):\n",
        "        result = list()\n",
        "        for idx, item in enumerate(data):\n",
        "            if item['type'] != 'SINGLE_SELECT': continue # Todo: Remove\n",
        "\n",
        "            # Pick a random answer and remove it from the answer pool\n",
        "            # Todo: Pfusch pls fix\n",
        "            # Todo: Remove answer from list of possible answers, e.g., w/ pop()\n",
        "            answer_list = list(answers_for_questions[idx].values())[0]\n",
        "            random_answer = random.choice(answer_list)\n",
        "            answer_key, answer_value = list(random_answer.items())[0]\n",
        "\n",
        "            result.append({\n",
        "                \"qid\": item['id'], # ID of question\n",
        "                \"question\": item['question'], # question as text\n",
        "                \"answer\": answer_key, # answer text of user\n",
        "                \"check_aid\": answer_value # ID of the intended answer to evaluate its correctness later\n",
        "            })\n",
        "\n",
        "        # Save to a new JSON file\n",
        "        output_filename = f\"userdata/q{questionnaire}_{generate_random_timestamp()}.json\"\n",
        "        with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "            json.dump(result, f, ensure_ascii=False, indent=4)\n",
        "        print(f\"Answer sheet {sheet} saved to file: {output_filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "id": "SnzogPXYxvrX",
        "outputId": "ebfd9e66-da13-4287-afd1-6cb00f5634b6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved file: questionnaire1.json\n",
            "Generated answers for question 'Data processing consent'.\n",
            "Generated answers for question 'Customer group'.\n",
            "Answer sheet 1 saved to file: userdata/q1_20241217_162024.json\n",
            "Answer sheet 2 saved to file: userdata/q1_20241205_151048.json\n",
            "Answer sheet 3 saved to file: userdata/q1_20241121_091448.json\n",
            "Answer sheet 4 saved to file: userdata/q1_20241214_043350.json\n",
            "Answer sheet 5 saved to file: userdata/q1_20241213_040341.json\n",
            "Retrieved file: questionnaire2.json\n",
            "Generated answers for question 'Would you like to receive marketing information from via e-mail?'.\n",
            "Generated answers for question 'What industry are you operating in?'.\n",
            "Answer sheet 1 saved to file: userdata/q2_20241218_031258.json\n",
            "Answer sheet 2 saved to file: userdata/q2_20241217_164605.json\n",
            "Answer sheet 3 saved to file: userdata/q2_20241126_113815.json\n",
            "Answer sheet 4 saved to file: userdata/q2_20241218_182606.json\n",
            "Answer sheet 5 saved to file: userdata/q2_20241219_231508.json\n",
            "Retrieved file: questionnaire3.json\n",
            "Generated answers for question 'What type of company is it?'.\n",
            "Generated answers for question 'What is the size of your company?'.\n",
            "Answer sheet 1 saved to file: userdata/q3_20241123_133342.json\n",
            "Answer sheet 2 saved to file: userdata/q3_20241203_024423.json\n",
            "Answer sheet 3 saved to file: userdata/q3_20241202_111154.json\n",
            "Answer sheet 4 saved to file: userdata/q3_20241203_150646.json\n",
            "Answer sheet 5 saved to file: userdata/q3_20241218_024145.json\n",
            "Retrieved file: questionnaire4.json\n",
            "Generated answers for question 'Which language is wanted for communication? '.\n",
            "Answer sheet 1 saved to file: userdata/q4_20241214_190018.json\n",
            "Answer sheet 2 saved to file: userdata/q4_20241206_014320.json\n",
            "Answer sheet 3 saved to file: userdata/q4_20241122_203051.json\n",
            "Answer sheet 4 saved to file: userdata/q4_20241205_060950.json\n",
            "Answer sheet 5 saved to file: userdata/q4_20241215_092003.json\n",
            "Retrieved file: questionnaire5.json\n",
            "Generated answers for question 'Customer type'.\n",
            "Generated answers for question 'Customer satisfaction'.\n",
            "Generated answers for question 'Size of the trade fair team (on average)'.\n",
            "Generated answers for question 'CRM-System'.\n",
            "Generated answers for question 'Next steps'.\n",
            "Answer sheet 1 saved to file: userdata/q5_20241129_112604.json\n",
            "Answer sheet 2 saved to file: userdata/q5_20241122_090651.json\n",
            "Answer sheet 3 saved to file: userdata/q5_20241205_072116.json\n",
            "Answer sheet 4 saved to file: userdata/q5_20241218_152352.json\n",
            "Answer sheet 5 saved to file: userdata/q5_20241204_024835.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Large dataset --> 1 step further"
      ],
      "metadata": {
        "id": "7JNd5fHgo-Lz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = list()\n",
        "\n",
        "# For each questionnaire (named 1-5)\n",
        "for questionnaire in range(1, 6):\n",
        "    url = f'https://raw.githubusercontent.com/croco22/CapstoneProjectTDS/refs/heads/main/questionnaires/questionnaire{questionnaire}.json'\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        print(f\"Retrieved file: questionnaire{questionnaire}.json\")\n",
        "    else:\n",
        "        print(\"Error while parsing a file: \", response.status_code)\n",
        "\n",
        "    # Generate dataset with all generated answers\n",
        "    for item in data:\n",
        "        if item['type'] != 'SINGLE_SELECT': continue # Todo: Remove\n",
        "        answer_list = process_question(item)\n",
        "        for answer in answer_list:\n",
        "          answer_key, answer_value = list(answer.items())[0]\n",
        "          result.append({\n",
        "              \"qid\": item['id'], # ID of question\n",
        "              \"question\": item['question'], # question as text\n",
        "              \"answer\": answer_key, # answer text of user\n",
        "              \"check_aid\": answer_value # ID of the intended answer to evaluate its correctness later\n",
        "          })\n",
        "        print(f\"Generated answers for question '{item['question']}'.\")\n",
        "\n",
        "# Save to a new JSON file\n",
        "with open(\"qa_dataset.json\", 'w', encoding='utf-8') as f:\n",
        "    json.dump(result, f, ensure_ascii=False, indent=4)\n",
        "print(\"Q&A dataset saved to file: qa_dataset.json\")"
      ],
      "metadata": {
        "id": "13UftBzMo1nk",
        "outputId": "eeee4396-b76e-4d06-865f-eedffd008bc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved file: questionnaire1.json\n",
            "Generated answers for question 'Data processing consent'.\n",
            "Generated answers for question 'Customer group'.\n",
            "Retrieved file: questionnaire2.json\n",
            "Generated answers for question 'Would you like to receive marketing information from via e-mail?'.\n",
            "Generated answers for question 'What industry are you operating in?'.\n",
            "Retrieved file: questionnaire3.json\n",
            "Generated answers for question 'What type of company is it?'.\n",
            "Generated answers for question 'What is the size of your company?'.\n",
            "Retrieved file: questionnaire4.json\n",
            "Generated answers for question 'Which language is wanted for communication? '.\n",
            "Retrieved file: questionnaire5.json\n",
            "Generated answers for question 'Customer type'.\n",
            "Generated answers for question 'Customer satisfaction'.\n",
            "Generated answers for question 'Size of the trade fair team (on average)'.\n",
            "Generated answers for question 'CRM-System'.\n",
            "Generated answers for question 'Next steps'.\n",
            "Q&A dataset saved to file: qa_dataset.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Todo: Generate more data based on this dataset"
      ],
      "metadata": {
        "id": "xj-kHoWQrP8X"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}