{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/croco22/CapstoneProjectTDS/blob/dev/notebooks/Generate_QA_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1: Generate Q&A Dataset"
      ],
      "metadata": {
        "id": "08r_8_xsdHfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import time\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import requests\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "from itertools import combinations\n",
        "import os\n",
        "\n",
        "# Create userdata folder in Colab environment\n",
        "if not os.path.exists(\"userdata\"):\n",
        "    os.mkdir(\"userdata\")\n",
        "\n",
        "# API setup\n",
        "key = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=key)\n",
        "ai_model = genai.GenerativeModel('gemini-1.5-flash')"
      ],
      "metadata": {
        "id": "jgaZ4x_pZ2JI"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_random_timestamp():\n",
        "    \"\"\"\n",
        "    Generate random timestamp within the last 30 days in the format '%Y%m%d_%H%M%S'.\n",
        "    \"\"\"\n",
        "    start_date = datetime.now() - timedelta(days=30)\n",
        "    random_seconds = random.randint(0, 30 * 24 * 60 * 60)\n",
        "    random_date = start_date + timedelta(seconds=random_seconds)\n",
        "    return random_date.strftime('%Y%m%d_%H%M%S')"
      ],
      "metadata": {
        "id": "J6MJrX3XFEDw"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define modules to process different types of data\n",
        "### Handler method"
      ],
      "metadata": {
        "id": "yvndzq1kaIs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_question(data):\n",
        "    \"\"\"\n",
        "    Generate spoken answers for the passed question in the JSON data.\n",
        "    A distinction is made between the different types of questions.\n",
        "    \"\"\"\n",
        "    type_handlers = {\n",
        "        \"SINGLE_SELECT\": handle_single_select,\n",
        "        \"MULTI_SELECT\": handle_multi_select,\n",
        "        \"TEXT\": handle_text,\n",
        "        \"NUMBER\": handle_number,\n",
        "        \"DATE\": handle_date,\n",
        "    }\n",
        "\n",
        "    data_type = data.get('type')\n",
        "    handler = type_handlers.get(data_type)\n",
        "\n",
        "    if handler:\n",
        "        return handler(data)\n",
        "    else:\n",
        "        exit(f\"Unhandled data type: {data_type}\")"
      ],
      "metadata": {
        "id": "DNRhF_GnXzGh"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Single Select"
      ],
      "metadata": {
        "id": "kpYJVGa3EciK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_single_select(data):\n",
        "    \"\"\"\n",
        "    Example output:\n",
        "    [\n",
        "      {\"Yeah, sure thing, ...\": [\"Yes\"]},\n",
        "      {\"Nope, I'd rather ...\": [\"No\"]},\n",
        "      ...\n",
        "    ]\n",
        "    \"\"\"\n",
        "    answers = list()\n",
        "    for option in data['options']:\n",
        "        response_text = generate_single_answers(item['question'], option['option'])\n",
        "        texts_array = [answer.strip() for answer in response_text.split(\"§\")]\n",
        "\n",
        "        for text in texts_array:\n",
        "          answers.append({\n",
        "              text: [option['option']]\n",
        "          })\n",
        "\n",
        "        time.sleep(3) # Required in the free version to avoid exceeding API limits\n",
        "    return answers\n",
        "\n",
        "\n",
        "def generate_single_answers(question, option):\n",
        "    \"\"\"\n",
        "    API call to generate spoken answers for each option.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    You are the user of an app and you are responding in a spoken style to the following question.\n",
        "    You like to talk so you don't just say yes or no but rather answer with a whole sentence.\n",
        "    Question: '{question}'\n",
        "    Your answer should contain the following content, e.g. if the content is 'yes', you convey this in your response.\n",
        "    The content must be stated explicitly in your answer.\n",
        "    Content of the answer: '{option}'\n",
        "    The responses should be in the following format and be random so each answer has to be different.\n",
        "    Generate 5 answers that are split by a § sign and contain only text.\n",
        "    answer1§answer2§...§answer5\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = ai_model.generate_content(prompt)\n",
        "        return response.text.strip()\n",
        "    except Exception as e:\n",
        "        exit(\"Error during API call: \", e)"
      ],
      "metadata": {
        "id": "l76F8RJuaBQM"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi Select"
      ],
      "metadata": {
        "id": "xydEZqimEea3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_multi_select(data):\n",
        "    \"\"\"\n",
        "    Generates responses for multi-select questions.\n",
        "    Example output:\n",
        "    [\n",
        "        {\"Yeah, that would be MY-SYSTEM and Notion, ...\": [\"MY-SYSTEM\", \"Notion\"]},\n",
        "        {\"Hmm, I think I'm mainly interested in Notion ...\": [\"Notion\"]},\n",
        "        ...\n",
        "    ]\n",
        "    \"\"\"\n",
        "    answers = list()\n",
        "    options = [option['option'] for option in data['options']]\n",
        "\n",
        "    # Generate all possible combinations of options (subsets)\n",
        "    all_combinations = []\n",
        "    for r in range(1, len(options) + 1):\n",
        "        all_combinations.extend(list(combinations(options, r)))\n",
        "\n",
        "    # Shuffle combinations for randomness\n",
        "    random.shuffle(all_combinations)\n",
        "\n",
        "    # Only generate answers for a random sample of combinations\n",
        "    selected_combinations = random.sample(all_combinations, min(5, len(all_combinations)))\n",
        "\n",
        "    for combo in selected_combinations:\n",
        "        response_text = generate_multi_answers(data['question'], combo)\n",
        "        texts_array = [answer.strip() for answer in response_text.split(\"§\")]\n",
        "\n",
        "        for text in texts_array:\n",
        "            answers.append({\n",
        "                text: list(combo)  # Store the options as a list\n",
        "            })\n",
        "\n",
        "        time.sleep(3)  # Avoid exceeding API limits in the free version\n",
        "    return answers\n",
        "\n",
        "\n",
        "def generate_multi_answers(question, options):\n",
        "    \"\"\"\n",
        "    API call to generate spoken answers for multiple options.\n",
        "    \"\"\"\n",
        "    options_text = \", \".join(options)\n",
        "    prompt = f\"\"\"\n",
        "    You are the user of an app and you are responding in a spoken style to the following question.\n",
        "    You like to talk so you don't just list options but rather answer with a whole sentence.\n",
        "    Question: '{question}'\n",
        "    Your answer has to contain all of the following text elements explicity to be valid: '{options_text}'.\n",
        "    The responses should be in the following format and random so each answer has to be different.\n",
        "    Generate 5 answers that are split by a § sign and contain only text.\n",
        "    answer1§answer2§...§answer5\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = ai_model.generate_content(prompt)\n",
        "        return response.text.strip()\n",
        "    except Exception as e:\n",
        "        exit(\"Error during API call: \", e)"
      ],
      "metadata": {
        "id": "g2RIpuQdltm8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text"
      ],
      "metadata": {
        "id": "PGDzZG4JEgjB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "xQdppMZmZv4W"
      },
      "outputs": [],
      "source": [
        "def handle_text(data):\n",
        "    # Todo\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number"
      ],
      "metadata": {
        "id": "njIon53CEkzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_number(data):\n",
        "    # Todo\n",
        "    pass"
      ],
      "metadata": {
        "id": "8uyF08h6Em6v"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Date"
      ],
      "metadata": {
        "id": "S3gdjp9sEjZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_date(data):\n",
        "    \"\"\"\n",
        "    Example output:\n",
        "    [\n",
        "        {\"Tomorrow would be good ...\": [86400]},\n",
        "        {\"How about in three weeks ...\": [1814400]},\n",
        "        ...\n",
        "    ]\n",
        "    \"\"\"\n",
        "    answers = list()\n",
        "    for option in data['options']:\n",
        "        response_text = generate_date_answers(item['question'])\n",
        "        texts_array = [answer.strip() for answer in response_text.split(\"§\")]\n",
        "\n",
        "        texts = texts_array[:5]\n",
        "        calculations = texts_array[5:]\n",
        "\n",
        "        for i in range(5):\n",
        "            answers.append({\n",
        "                texts[i]: [int(calculations[i])]\n",
        "            })\n",
        "\n",
        "        time.sleep(3) # Required in the free version to avoid exceeding API limits\n",
        "    return answers\n",
        "\n",
        "\n",
        "def generate_date_answers(question):\n",
        "    \"\"\"\n",
        "    Generates responses for date questions.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    You are the user of an app and you are responding in a spoken style to the following question.\n",
        "    You like to talk so you don't just say yes or no but rather answer with a whole sentence.\n",
        "    Question: '{question}'\n",
        "    Your answer should contain a time reference in the future, such as 'tomorrow', 'in three weeks', etc.\n",
        "    Additionally you have to give a calculation reference for this in seconds without naming a fixed date, e.g. 'tomorrow'=86.400; 'in three weeks'=1.814.400\n",
        "    The responses should be in the following format and be random so each answer has to be different.\n",
        "    Generate 5 answers that are split by a § sign and contain only text.\n",
        "    After that follow the calculation references seperated by a § sign as Integer values.\n",
        "    answer1§answer2§...§answer5§calculation1§calculation2§...§calculation5\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = ai_model.generate_content(prompt)\n",
        "        return response.text.strip()\n",
        "    except Exception as e:\n",
        "        exit(\"Error during API call: \", e)"
      ],
      "metadata": {
        "id": "ONp8EhOrEokg"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run defined modules for each question provided and save to a JSON-file\n",
        "### Simulate real world questionnaires"
      ],
      "metadata": {
        "id": "TJ-E8toBbBs4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Currently questionnaire 3 & 4 selected\n",
        "for questionnaire in [3, 4]:\n",
        "    url = f'https://raw.githubusercontent.com/croco22/CapstoneProjectTDS/refs/heads/main/questionnaires/questionnaire{questionnaire}.json'\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        print(f\"Retrieved file: questionnaire{questionnaire}.json\")\n",
        "    else:\n",
        "        print(\"Error while parsing a file: \", response.status_code)\n",
        "\n",
        "    # Generate a set of possible answer texts\n",
        "    answers_for_questions = list()\n",
        "    for item in data:\n",
        "        if item['type'] not in ['SINGLE_SELECT', 'MULTI_SELECT', 'DATE']: # Todo: Remove\n",
        "            answers_for_questions.append({})\n",
        "            continue\n",
        "\n",
        "        answers_for_questions.append({\n",
        "            item['id']: process_question(item)\n",
        "        })\n",
        "        print(f\"Generated answers for question '{item['question']}'.\")\n",
        "\n",
        "    # Generate 5 answer sheets\n",
        "    for sheet in range(1, 6):\n",
        "        result = list()\n",
        "        for idx, item in enumerate(data):\n",
        "            if item['type'] not in ['SINGLE_SELECT', 'MULTI_SELECT', 'DATE']: continue # Todo: Remove\n",
        "\n",
        "            # Pick a random answer from the answer pool\n",
        "            answer_list = list(answers_for_questions[idx].values())[0]\n",
        "            random_answer = random.choice(answer_list)\n",
        "            answer_key, answer_value = list(random_answer.items())[0]\n",
        "\n",
        "            result.append({\n",
        "                \"question\": item['question'], # question as a String\n",
        "                \"possible_answers\": [option['option'] for option in item['options']], # Possible answer Strings\n",
        "                \"answer_text\": answer_key, # Answer text of user\n",
        "                \"intended_answer\": answer_value # Intended answers to evaluate later\n",
        "            })\n",
        "\n",
        "        # Save the sheet to a new JSON file\n",
        "        output_filename = f\"userdata/q{questionnaire}_{generate_random_timestamp()}.json\"\n",
        "        with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "            json.dump(result, f, ensure_ascii=False, indent=4)\n",
        "        print(f\"Answer sheet {sheet} saved to file: {output_filename}\")"
      ],
      "metadata": {
        "id": "SnzogPXYxvrX",
        "collapsed": true,
        "outputId": "fecd2a05-91b7-4321-e8dc-a06f367978a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved file: questionnaire3.json\n",
            "Generated answers for question 'What type of company is it?'.\n",
            "Generated answers for question 'What is the size of your company?'.\n",
            "Generated answers for question 'When do you wish to receive a follow-up?'.\n",
            "Answer sheet 1 saved to file: userdata/q3_20241224_212503.json\n",
            "Answer sheet 2 saved to file: userdata/q3_20241216_002453.json\n",
            "Answer sheet 3 saved to file: userdata/q3_20241212_032513.json\n",
            "Answer sheet 4 saved to file: userdata/q3_20250104_114335.json\n",
            "Answer sheet 5 saved to file: userdata/q3_20241228_170057.json\n",
            "Retrieved file: questionnaire4.json\n",
            "Generated answers for question 'Which language is wanted for communication? '.\n",
            "Generated answers for question 'What is the type of contact?'.\n",
            "Generated answers for question 'What is the contact person interested in?'.\n",
            "Generated answers for question 'When does the contact person wish to receive a follow up?'.\n",
            "Answer sheet 1 saved to file: userdata/q4_20241226_222337.json\n",
            "Answer sheet 2 saved to file: userdata/q4_20241229_193841.json\n",
            "Answer sheet 3 saved to file: userdata/q4_20250108_212713.json\n",
            "Answer sheet 4 saved to file: userdata/q4_20250102_122333.json\n",
            "Answer sheet 5 saved to file: userdata/q4_20250109_133045.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate large dataset"
      ],
      "metadata": {
        "id": "7JNd5fHgo-Lz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# result = list()\n",
        "\n",
        "# # For each questionnaire (named 1-5)\n",
        "# for questionnaire in range(1, 6):\n",
        "#     url = f'https://raw.githubusercontent.com/croco22/CapstoneProjectTDS/refs/heads/main/questionnaires/questionnaire{questionnaire}.json'\n",
        "#     response = requests.get(url)\n",
        "\n",
        "#     if response.status_code == 200:\n",
        "#         data = response.json()\n",
        "#         print(f\"Retrieved file: questionnaire{questionnaire}.json\")\n",
        "#     else:\n",
        "#         print(\"Error while parsing a file: \", response.status_code)\n",
        "\n",
        "#     # Generate dataset with all generated answers\n",
        "#     for item in data:\n",
        "#         if item['type'] != 'SINGLE_SELECT' and item['type'] != 'MULTI_SELECT': continue # Todo: Remove\n",
        "\n",
        "#         answer_list = process_question(item)\n",
        "#         for answer in answer_list:\n",
        "#           answer_key, answer_value = list(answer.items())[0]\n",
        "#           result.append({\n",
        "#               \"question\": item['question'], # question as a String\n",
        "#               \"possible_answers\": [option['option'] for option in item['options']], # Possible answer Strings\n",
        "#               \"answer_text\": answer_key, # Answer text of user\n",
        "#               \"intended_answer\": answer_value # Intended answer to evaluate later\n",
        "#           })\n",
        "#         print(f\"Generated answers for question '{item['question']}'.\")\n",
        "\n",
        "# # Save dataset to a new JSON file\n",
        "# with open(\"qa_dataset.json\", 'w', encoding='utf-8') as f:\n",
        "#     json.dump(result, f, ensure_ascii=False, indent=4)\n",
        "# print(\"Q&A dataset saved to file: qa_dataset.json\")"
      ],
      "metadata": {
        "id": "13UftBzMo1nk"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download all created files"
      ],
      "metadata": {
        "id": "V1mar6azFXyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "\n",
        "# # Download files\n",
        "# !zip userdata.zip userdata/*\n",
        "# files.download('userdata.zip')\n",
        "# files.download('qa_dataset.json')"
      ],
      "metadata": {
        "id": "thqXWFmyWpUo"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Todo: Generate more data based on this dataset\n",
        "# Should we convert the dataset in a pandas dataframe instead of a dict?"
      ],
      "metadata": {
        "id": "xj-kHoWQrP8X"
      },
      "execution_count": 33,
      "outputs": []
    }
  ]
}