{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/croco22/CapstoneProjectTDS/blob/branch_philipp/notebooks/Generate_QA_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1: Generate Q&A Dataset"
      ],
      "metadata": {
        "id": "08r_8_xsdHfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import time\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import requests\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Create userdata folder in Colab environment\n",
        "!mkdir userdata\n",
        "\n",
        "# API setup\n",
        "key = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=key)\n",
        "ai_model = genai.GenerativeModel('gemini-1.5-flash')"
      ],
      "metadata": {
        "id": "jgaZ4x_pZ2JI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define modules to process different types of data"
      ],
      "metadata": {
        "id": "yvndzq1kaIs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_question(data):\n",
        "    \"\"\"\n",
        "    Generate spoken answers for the passed question in the JSON data.\n",
        "    A distinction is made between the different types of questions.\n",
        "    \"\"\"\n",
        "    type_handlers = {\n",
        "        \"SINGLE_SELECT\": handle_single_select,\n",
        "        \"MULTI_SELECT\": handle_multi_select,\n",
        "        \"TEXT\": handle_text,\n",
        "        \"DATE\": handle_date,\n",
        "        \"NUMBER\": handle_number,\n",
        "    }\n",
        "\n",
        "    data_type = data.get('type')\n",
        "    handler = type_handlers.get(data_type)\n",
        "\n",
        "    if handler:\n",
        "        return handler(data)\n",
        "    else:\n",
        "        exit(f\"Unhandled data type: {data_type}\")"
      ],
      "metadata": {
        "id": "DNRhF_GnXzGh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_single_select(data):\n",
        "    \"\"\"\n",
        "    Example output:\n",
        "    [{\"Yeah, sure thing, ...\": \"Yes\"},\n",
        "    {\"Okay, yes, ...\": \"Yes\"},\n",
        "    ...,\n",
        "    {\"Nope, I'd rather ...\": \"No\"},\n",
        "    {\"Nah, I'm not ...\": \"No\"},\n",
        "    ...]\n",
        "    \"\"\"\n",
        "    answers = list()\n",
        "    for option in data['options']:\n",
        "        response_text = generate_single_answers(item['question'], option['option'])\n",
        "        texts_array = [answer.strip() for answer in response_text.split(\"§\")]\n",
        "\n",
        "        for text in texts_array:\n",
        "          answers.append({\n",
        "              text: option['option']\n",
        "          })\n",
        "\n",
        "        time.sleep(3) # Required in the free version to avoid exceeding API limits\n",
        "    return answers\n",
        "\n",
        "def handle_multi_select(data):\n",
        "    \"\"\"\n",
        "    Generates responses for multi-select questions.\n",
        "    Example output:\n",
        "    [\n",
        "        {\"Yeah, that would be MY-SYSTEM and Notion, ...\": [\"MY-SYSTEM\", \"Notion\"]},\n",
        "        {\"Hmm, I think I'm mainly interested in Notion ...\": [\"Notion\"]},\n",
        "        ...\n",
        "    ]\n",
        "    \"\"\"\n",
        "    from itertools import combinations\n",
        "    import random\n",
        "\n",
        "    answers = list()\n",
        "    options = [option['option'] for option in data['options']]\n",
        "\n",
        "    # Generate all possible combinations of options (subsets)\n",
        "    all_combinations = []\n",
        "    for r in range(1, len(options) + 1):\n",
        "        all_combinations.extend(list(combinations(options, r)))\n",
        "\n",
        "    # Shuffle combinations for randomness\n",
        "    random.shuffle(all_combinations)\n",
        "\n",
        "    # Only generate answers for a random sample of combinations\n",
        "    selected_combinations = random.sample(all_combinations, min(5, len(all_combinations)))\n",
        "\n",
        "    for combo in selected_combinations:\n",
        "        response_text = generate_multi_answers(data['question'], combo)\n",
        "        texts_array = [answer.strip() for answer in response_text.split(\"§\")]\n",
        "\n",
        "        for text in texts_array:\n",
        "            answers.append({\n",
        "                text: list(combo)  # Store the options as a list\n",
        "            })\n",
        "\n",
        "        time.sleep(3)  # Avoid exceeding API limits in the free version\n",
        "    return answers\n",
        "\n",
        "\n",
        "\n",
        "def handle_text(data):\n",
        "    # Todo\n",
        "    pass\n",
        "\n",
        "def handle_date(data):\n",
        "    # Todo\n",
        "    pass\n",
        "\n",
        "def handle_number(data):\n",
        "    # Todo\n",
        "    pass"
      ],
      "metadata": {
        "id": "l76F8RJuaBQM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define module to generate text via API including AI prompts"
      ],
      "metadata": {
        "id": "A7bEJzqMavni"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xQdppMZmZv4W"
      },
      "outputs": [],
      "source": [
        "def generate_single_answers(question, option):\n",
        "    \"\"\"\n",
        "    API call to generate spoken answers for each option.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    You are the user of an app and you are responding in a spoken style to the following question.\n",
        "    You like to talk so you don't just say yes or no but rather answer with a whole sentence.\n",
        "    Question: \"{question}\"\n",
        "    Your answer should contain the following content, e.g. if the content is \"yes\", you convey this in your response. The content must be stated explicitly in your answer.:\n",
        "    Content of the answer: \"{option}\"\n",
        "    The responses should be in the following format and be kind of random so that each answer is in a different style.\n",
        "    Generate 5 answers that are split by a § sign and contain only text.\n",
        "    answer1§answer2§...§answer5\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = ai_model.generate_content(prompt)\n",
        "        return response.text.strip()\n",
        "    except Exception as e:\n",
        "        exit(\"Error during API call: \", e)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_multi_answers(question, options):\n",
        "    \"\"\"\n",
        "    API call to generate spoken answers for multiple options.\n",
        "    \"\"\"\n",
        "    options_text = \", \".join(options)\n",
        "    prompt = f\"\"\"\n",
        "    You are the user of an app and you are responding in a spoken style to the following question.\n",
        "    You like to talk so you don't just list options but rather answer with a whole sentence.\n",
        "    Question: \"{question}\"\n",
        "    Your answer has to contain all of the following text elements explicity to be valid: \"{options_text}\".\n",
        "    The responses should be in the following format and be kind of random so that each answer is in a different style.\n",
        "    Generate 5 answers that are split by a § sign and contain only text.\n",
        "    answer1§answer2§...§answer5\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = ai_model.generate_content(prompt)\n",
        "        return response.text.strip()\n",
        "    except Exception as e:\n",
        "        exit(\"Error during API call: \", e)"
      ],
      "metadata": {
        "id": "g2RIpuQdltm8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run defined modules for each question provided and save to a JSON-file"
      ],
      "metadata": {
        "id": "TJ-E8toBbBs4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_random_timestamp():\n",
        "    \"\"\"\n",
        "    Generate random timestamp within the last 30 days in the format '%Y%m%d_%H%M%S'.\n",
        "    \"\"\"\n",
        "    start_date = datetime.now() - timedelta(days=30)\n",
        "    random_seconds = random.randint(0, 30 * 24 * 60 * 60)\n",
        "    random_date = start_date + timedelta(seconds=random_seconds)\n",
        "    return random_date.strftime('%Y%m%d_%H%M%S')"
      ],
      "metadata": {
        "id": "ZABYLjJCdCF7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Close to real-word application"
      ],
      "metadata": {
        "id": "OEop2y31o6tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For each questionnaire (named 1-5)\n",
        "for questionnaire in range(1, 6):\n",
        "    url = f'https://raw.githubusercontent.com/croco22/CapstoneProjectTDS/refs/heads/main/questionnaires/questionnaire{questionnaire}.json'\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        print(f\"Retrieved file: questionnaire{questionnaire}.json\")\n",
        "    else:\n",
        "        print(\"Error while parsing a file: \", response.status_code)\n",
        "\n",
        "    # Generate a set of possible answer texts\n",
        "    answers_for_questions = list()\n",
        "    for item in data:\n",
        "        if item['type'] != 'SINGLE_SELECT' and item['type'] != 'MULTI_SELECT': # Todo: Remove\n",
        "            answers_for_questions.append({})\n",
        "            continue\n",
        "\n",
        "        answers_for_questions.append({\n",
        "            item['id']: process_question(item)\n",
        "        })\n",
        "        print(f\"Generated answers for question '{item['question']}'.\")\n",
        "\n",
        "    # Generate 5 answer sheets\n",
        "    for sheet in range(1, 6):\n",
        "        result = list()\n",
        "        for idx, item in enumerate(data):\n",
        "            if item['type'] != 'SINGLE_SELECT' and item['type'] != 'MULTI_SELECT': continue # Todo: Remove\n",
        "\n",
        "            # Pick a random answer from the answer pool\n",
        "            answer_list = list(answers_for_questions[idx].values())[0]\n",
        "            random_answer = random.choice(answer_list)\n",
        "            answer_key, answer_value = list(random_answer.items())[0]\n",
        "\n",
        "            result.append({\n",
        "                \"question\": item['question'], # question as a String\n",
        "                \"possible_answers\": [option['option'] for option in item['options']], # Possible answer Strings\n",
        "                \"answer_text\": answer_key, # Answer text of user\n",
        "                \"intended_answer\": answer_value # Intended answer to evaluate later\n",
        "            })\n",
        "\n",
        "        # Save the sheet to a new JSON file\n",
        "        output_filename = f\"userdata/q{questionnaire}_{generate_random_timestamp()}.json\"\n",
        "        with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "            json.dump(result, f, ensure_ascii=False, indent=4)\n",
        "        print(f\"Answer sheet {sheet} saved to file: {output_filename}\")"
      ],
      "metadata": {
        "id": "SnzogPXYxvrX",
        "collapsed": true,
        "outputId": "9ca4b9f4-0078-4324-8bbd-0875972c6c04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 902
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved file: questionnaire1.json\n",
            "Generated answers for question 'Data processing consent'.\n",
            "Generated answers for question 'Customer group'.\n",
            "Generated answers for question 'Products interested in'.\n",
            "Generated answers for question 'What kind of follow up is planned'.\n",
            "Generated answers for question 'Who to copy in follow up'.\n",
            "Answer sheet 1 saved to file: userdata/q1_20241215_193136.json\n",
            "Answer sheet 2 saved to file: userdata/q1_20241231_122029.json\n",
            "Answer sheet 3 saved to file: userdata/q1_20250104_212235.json\n",
            "Answer sheet 4 saved to file: userdata/q1_20241210_054342.json\n",
            "Answer sheet 5 saved to file: userdata/q1_20241222_051914.json\n",
            "Retrieved file: questionnaire2.json\n",
            "Generated answers for question 'Would you like to receive marketing information from via e-mail?'.\n",
            "Generated answers for question 'What industry are you operating in?'.\n",
            "Generated answers for question 'What products are you interested in?'.\n",
            "Answer sheet 1 saved to file: userdata/q2_20250101_183928.json\n",
            "Answer sheet 2 saved to file: userdata/q2_20250103_132841.json\n",
            "Answer sheet 3 saved to file: userdata/q2_20241231_144249.json\n",
            "Answer sheet 4 saved to file: userdata/q2_20241218_094151.json\n",
            "Answer sheet 5 saved to file: userdata/q2_20241228_133127.json\n",
            "Retrieved file: questionnaire3.json\n",
            "Generated answers for question 'What type of company is it?'.\n",
            "Generated answers for question 'What is the size of your company?'.\n",
            "Answer sheet 1 saved to file: userdata/q3_20250108_115042.json\n",
            "Answer sheet 2 saved to file: userdata/q3_20250108_063335.json\n",
            "Answer sheet 3 saved to file: userdata/q3_20250104_225002.json\n",
            "Answer sheet 4 saved to file: userdata/q3_20241228_191649.json\n",
            "Answer sheet 5 saved to file: userdata/q3_20241229_090910.json\n",
            "Retrieved file: questionnaire4.json\n",
            "Generated answers for question 'Which language is wanted for communication? '.\n",
            "Generated answers for question 'What is the type of contact?'.\n",
            "Generated answers for question 'What is the contact person interested in?'.\n",
            "Generated answers for question 'When does the contact person wish to receive a follow up?'.\n",
            "Answer sheet 1 saved to file: userdata/q4_20241214_225006.json\n",
            "Answer sheet 2 saved to file: userdata/q4_20241220_162934.json\n",
            "Answer sheet 3 saved to file: userdata/q4_20241220_155856.json\n",
            "Answer sheet 4 saved to file: userdata/q4_20241225_141244.json\n",
            "Answer sheet 5 saved to file: userdata/q4_20241223_204513.json\n",
            "Retrieved file: questionnaire5.json\n",
            "Generated answers for question 'Customer type'.\n",
            "Generated answers for question 'Customer satisfaction'.\n",
            "Generated answers for question 'Size of the trade fair team (on average)'.\n",
            "Generated answers for question 'CRM-System'.\n",
            "Generated answers for question 'Productinterests'.\n",
            "Generated answers for question 'Searches a solution for'.\n",
            "Generated answers for question 'Next steps'.\n",
            "Answer sheet 1 saved to file: userdata/q5_20241215_210852.json\n",
            "Answer sheet 2 saved to file: userdata/q5_20241223_005312.json\n",
            "Answer sheet 3 saved to file: userdata/q5_20250105_213447.json\n",
            "Answer sheet 4 saved to file: userdata/q5_20250101_053222.json\n",
            "Answer sheet 5 saved to file: userdata/q5_20241217_015932.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Large dataset --> 1 step further"
      ],
      "metadata": {
        "id": "7JNd5fHgo-Lz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# result = list()\n",
        "\n",
        "# # For each questionnaire (named 1-5)\n",
        "# for questionnaire in range(1, 6):\n",
        "#     url = f'https://raw.githubusercontent.com/croco22/CapstoneProjectTDS/refs/heads/main/questionnaires/questionnaire{questionnaire}.json'\n",
        "#     response = requests.get(url)\n",
        "\n",
        "#     if response.status_code == 200:\n",
        "#         data = response.json()\n",
        "#         print(f\"Retrieved file: questionnaire{questionnaire}.json\")\n",
        "#     else:\n",
        "#         print(\"Error while parsing a file: \", response.status_code)\n",
        "\n",
        "#     # Generate dataset with all generated answers\n",
        "#     for item in data:\n",
        "#         if item['type'] != 'SINGLE_SELECT' and item['type'] != 'MULTI_SELECT': continue # Todo: Remove\n",
        "\n",
        "#         answer_list = process_question(item)\n",
        "#         for answer in answer_list:\n",
        "#           answer_key, answer_value = list(answer.items())[0]\n",
        "#           result.append({\n",
        "#               \"question\": item['question'], # question as a String\n",
        "#               \"possible_answers\": [option['option'] for option in item['options']], # Possible answer Strings\n",
        "#               \"answer_text\": answer_key, # Answer text of user\n",
        "#               \"intended_answer\": answer_value # Intended answer to evaluate later\n",
        "#           })\n",
        "#         print(f\"Generated answers for question '{item['question']}'.\")\n",
        "\n",
        "# # Save dataset to a new JSON file\n",
        "# with open(\"qa_dataset.json\", 'w', encoding='utf-8') as f:\n",
        "#     json.dump(result, f, ensure_ascii=False, indent=4)\n",
        "# print(\"Q&A dataset saved to file: qa_dataset.json\")"
      ],
      "metadata": {
        "id": "13UftBzMo1nk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "\n",
        "# # Download files\n",
        "# !zip userdata.zip userdata/*\n",
        "# files.download('userdata.zip')\n",
        "# files.download('qa_dataset.json')"
      ],
      "metadata": {
        "id": "thqXWFmyWpUo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Todo: Generate more data based on this dataset\n",
        "# Should we convert the dataset in a pandas dataframe instead of a dict?"
      ],
      "metadata": {
        "id": "xj-kHoWQrP8X"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}