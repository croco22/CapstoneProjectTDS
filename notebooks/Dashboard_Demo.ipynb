{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/croco22/CapstoneProjectTDS/blob/philipp/notebooks/Dashboard_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extra Task 3: Live Demo\n",
        "\n",
        "## Imports and Setup"
      ],
      "metadata": {
        "id": "a_5wicdWgEvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install gradio\n",
        "# !pip install git+https://github.com/openai/whisper.git\n",
        "!pip install SpeechRecognition\n",
        "!pip install qrcode[pil]\n",
        "\n",
        "import io\n",
        "import os\n",
        "# import logging\n",
        "import sys\n",
        "import time\n",
        "import re\n",
        "import requests\n",
        "from datetime import datetime\n",
        "\n",
        "import pandas as pd\n",
        "import qrcode\n",
        "# import whisper\n",
        "import speech_recognition as sr\n",
        "# from sklearn.metrics.pairwise import cosine_similarity\n",
        "# from sentence_transformers import SentenceTransformer\n",
        "from transformers import pipeline\n",
        "import gradio as gr\n",
        "import google.generativeai as genai\n",
        "from IPython.display import display, Image\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "recognizer = sr.Recognizer()\n",
        "# logging.basicConfig(level=logging.ERROR)\n",
        "\n",
        "# API Setup\n",
        "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "model = genai.GenerativeModel('gemini-2.0-flash-exp')\n",
        "userdata.get('HF_TOKEN')\n",
        "\n",
        "# Download favicon\n",
        "image_url = \"https://raw.githubusercontent.com/croco22/CapstoneProjectTDS/refs/heads/philipp/images/profile.jpg\" # Todo: Set to main branch\n",
        "img_data = requests.get(image_url).content\n",
        "with open('favicon.png', 'wb') as handler:\n",
        "    handler.write(img_data)\n",
        "\n",
        "\n",
        "def generate_text(prompt):\n",
        "    try:\n",
        "        response = model.generate_content(\n",
        "            prompt,\n",
        "            generation_config = genai.GenerationConfig(\n",
        "                temperature=2.0,\n",
        "            )\n",
        "        )\n",
        "        time.sleep(5) # Avoid exceeding API limits\n",
        "        return response.text.strip()\n",
        "    except Exception as e:\n",
        "        exit(\"Error during API call: \", e)"
      ],
      "metadata": {
        "id": "n3aIGKcngDpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data from the provided questionnaires"
      ],
      "metadata": {
        "id": "l6lNDb8ERWJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = list()\n",
        "\n",
        "for q in range(1, 6):\n",
        "    url = f'https://raw.githubusercontent.com/croco22/CapstoneProjectTDS/refs/heads/main/questionnaires/questionnaire{q}.json'\n",
        "    temp_df = pd.read_json(url)\n",
        "\n",
        "    # Unpack options into an array\n",
        "    temp_df['options'] = temp_df['options'].apply(lambda x: [option['option'] for option in x])\n",
        "\n",
        "    # Remove options for specific question types\n",
        "    # because irrelevant or do not contribute meaningfully to the dataset\n",
        "    temp_df.loc[temp_df['type'].isin(['TEXT', 'NUMBER', 'DATE']), 'options'] = None\n",
        "\n",
        "    temp_df['questionnaire'] = f\"Questionnaire {q}\"\n",
        "\n",
        "    dfs.append(temp_df)\n",
        "\n",
        "df = pd.concat(dfs, ignore_index=True)"
      ],
      "metadata": {
        "id": "FT5Y15cZQijj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rephrase questions if necessary"
      ],
      "metadata": {
        "id": "7A2T2D-_Ru2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rephrase_question(text):\n",
        "    prompt = f\"\"\"\n",
        "        Reformulate the following statement into a clear, concise, and\n",
        "        grammatically correct question that directly addresses the user. For\n",
        "        example, 'Do you consent to data processing?' or 'What kind of follow-up\n",
        "        would you prefer?'. If the text is already a question, preserve its\n",
        "        meaning and intent without altering the content or facts. The statement\n",
        "        is: '{text}'. Return only the reformulated question, without any\n",
        "        additional explanations, comments, or text.\n",
        "    \"\"\"\n",
        "    return generate_text(prompt)\n",
        "\n",
        "\n",
        "df['rephrased_question'] = df['question'].apply(rephrase_question)\n",
        "\n",
        "df = df[['questionnaire', 'type', 'rephrased_question', 'options']].copy()\n",
        "df['answer'] = \"<skipped by user>\"\n",
        "df['missed_count'] = 0\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "PRffJkreal_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate context\n",
        "The code selects the most relevant question from a list based on a combination of semantic similarity (using embeddings) and contextual relevance (using a question-answering model)."
      ],
      "metadata": {
        "id": "_i48UdQONz7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
        "# embedding_model = SentenceTransformer('all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "FUVvXbGZoxNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def evaluate_context(context, unanswered_questions):\n",
        "#     best_question = None\n",
        "#     highest_score = -1\n",
        "#     context_embedding = embedding_model.encode([context])\n",
        "\n",
        "#     for question in unanswered_questions:\n",
        "#         qa_result = qa_pipeline(question=question, context=context)\n",
        "#         score = qa_result['score']\n",
        "\n",
        "#         question_embedding = embedding_model.encode([question])\n",
        "#         similarity = cosine_similarity(context_embedding, question_embedding)[0][0]\n",
        "\n",
        "#         combined_score = score * similarity\n",
        "\n",
        "#         if combined_score > highest_score:\n",
        "#             highest_score = combined_score\n",
        "#             best_question = question\n",
        "\n",
        "#     return best_question\n",
        "\n",
        "\n",
        "# # def evaluate_answer(message, options):\n",
        "# #     message_embedding = embedding_model.encode([message])\n",
        "\n",
        "# #     highest_similarity = -1\n",
        "# #     best_answer = None\n",
        "\n",
        "# #     for option in options:\n",
        "# #         option_embedding = embedding_model.encode([option])\n",
        "# #         similarity = cosine_similarity([message_embedding[0]], [option_embedding[0]])[0][0]\n",
        "\n",
        "# #         if similarity > highest_similarity:\n",
        "# #             highest_similarity = similarity\n",
        "# #             best_answer = option\n",
        "\n",
        "# #     return best_answer"
      ],
      "metadata": {
        "id": "DETYkkFVdlvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "# classifier = pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\")\n",
        "\n",
        "def get_number(text):\n",
        "    prompt = f\"\"\"\n",
        "        Following text contains a phone number: '{text}'.\n",
        "        Extract the phone number and only return the phone number, without any\n",
        "        additional explanations, comments, or text.\n",
        "    \"\"\"\n",
        "    return generate_text(prompt)\n",
        "\n",
        "\n",
        "def get_date(text):\n",
        "    prompt = f\"\"\"\n",
        "        Following text contains a date/time reference: '{text}'.\n",
        "        Extract the time reference and return an integer value of this reference in seconds.\n",
        "        E.g. 'in three weeks' should return '1814400', 'tomorrow' should return '86400'.\n",
        "        Return the value without any additional explanations, comments, or text.\n",
        "    \"\"\"\n",
        "    result = generate_text(prompt)\n",
        "    try:\n",
        "        int_reference = int(result)\n",
        "    except ValueError:\n",
        "        int_reference = 0\n",
        "    current_time = datetime.utcnow()\n",
        "    future_time = current_time + pd.Timedelta(seconds=int_reference)\n",
        "    formatted_time = future_time.strftime(\"%d.%m.%Y, %H:%M Uhr\")\n",
        "    return formatted_time"
      ],
      "metadata": {
        "id": "3kJgCX3yyzpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_context(context, questions, qtype=None):\n",
        "    if qtype is None or qtype == \"SINGLE_SELECT\": # Clustering for qtype=None --> multi_label=True\n",
        "        question_results = classifier(context, candidate_labels=questions)\n",
        "        best_match = question_results[\"labels\"][0]\n",
        "        return best_match\n",
        "    elif qtype == \"MULTI_SELECT\":\n",
        "        question_results = classifier(context, candidate_labels=questions, multi_label=True)\n",
        "        best_matches = [\n",
        "            label for label, score in zip(question_results[\"labels\"], question_results[\"scores\"])\n",
        "            if score > 0.25\n",
        "        ]\n",
        "        return \", \".join(map(str, best_matches))\n",
        "    elif qtype == \"TEXT\":\n",
        "        return context\n",
        "    elif qtype == \"NUMBER\":\n",
        "        return get_number(context)\n",
        "    elif qtype == \"DATE\":\n",
        "        return get_date(context)\n",
        "    else:\n",
        "        return \"[ERROR] Evaluation not possible.\""
      ],
      "metadata": {
        "id": "J_FGXapaUI0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "        Following text contains a date/time reference: 'TOMORROW'.\n",
        "        Extract the time reference and return an integer value of this reference in seconds.\n",
        "        E.g. 'in three weeks' should return '1814400', 'tomorrow' should return '86400'.\n",
        "        Return the value without any additional explanations, comments, or text.\n",
        "    \"\"\"\n",
        "result = generate_text(prompt)"
      ],
      "metadata": {
        "id": "XLMgwaweJAda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_date(\"Tommorow pls\"))"
      ],
      "metadata": {
        "id": "yROLWcNbI4yN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradio application"
      ],
      "metadata": {
        "id": "YJ8BIxwGR9Kv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_message(message, unanswered_questions, df_v):\n",
        "    if isinstance(unanswered_questions, gr.State):\n",
        "        uq_list = unanswered_questions.value\n",
        "    else:\n",
        "        uq_list = unanswered_questions\n",
        "\n",
        "    real_question = evaluate_context(message, uq_list)\n",
        "    # for q in real_questions:\n",
        "    answer_options = df_v[df_v['rephrased_question'] == real_question]['options'].iloc[0]\n",
        "    qtype = df_v[df_v['rephrased_question'] == real_question]['type'].iloc[0]\n",
        "    df_v.loc[df_v['rephrased_question'] == real_question, 'answer'] = evaluate_context(message, answer_options, qtype)\n",
        "\n",
        "    real_idx = uq_list.index(real_question)\n",
        "    df_v.loc[(df_v['rephrased_question'].isin(uq_list[:real_idx])), 'missed_count'] += 1\n",
        "\n",
        "    uq_list.remove(real_question)\n",
        "\n",
        "    remaining_uq_list = [question for question in uq_list if df_v[df_v['rephrased_question'] == question]['missed_count'].iloc[0] <= 1]\n",
        "\n",
        "    return remaining_uq_list, df_v\n",
        "\n",
        "\n",
        "def set_response(unanswered_questions, df_v=None):\n",
        "    if isinstance(unanswered_questions, gr.State):\n",
        "        uq_list = unanswered_questions.value\n",
        "    else:\n",
        "        uq_list = unanswered_questions\n",
        "\n",
        "    if len(uq_list) == 0:\n",
        "            return \"Thank you! Please submit your responses via 'Send' :)\"\n",
        "\n",
        "    flag = False\n",
        "    if df_v is None:\n",
        "        unanswered_questions_string = '<ol style=\"font-size: 13px;\">' + ''.join([f'<li>{q}</li>' for q in uq_list]) + '</ol>'\n",
        "        response = f\"\"\"\n",
        "            <p>Please answer the following questions:</p>\n",
        "            <p>{unanswered_questions_string}</p>\n",
        "        \"\"\"\n",
        "    else:\n",
        "        unanswered_questions_string = '<ol style=\"font-size: 13px;\">'\n",
        "        for q in uq_list:\n",
        "            missed_count_row = df_v[df_v['rephrased_question'] == q]\n",
        "            missed_count = missed_count_row['missed_count'].iloc[0]\n",
        "            if missed_count == 1:\n",
        "                flag = True\n",
        "                unanswered_questions_string += f'<li style=\"color: #77f7d1;\">{q}</li>'\n",
        "            else:\n",
        "                unanswered_questions_string += f'<li>{q}</li>'\n",
        "\n",
        "    unanswered_questions_string += '</ol>'\n",
        "    if flag:\n",
        "        response = f\"\"\"\n",
        "            <p>Please answer the following questions<span style='color: #77f7d1;'>*</span>:</p>\n",
        "            <p>{unanswered_questions_string}</p>\n",
        "            <p style='color: #77f7d1; font-size: 10px;'>* Highlighted questions will be skipped if unanswered.</p>\n",
        "        \"\"\"\n",
        "    else:\n",
        "        response = f\"\"\"\n",
        "            <p>Please answer the following questions:</p>\n",
        "            <p>{unanswered_questions_string}</p>\n",
        "        \"\"\"\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "w-YiHZ1gNgLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def start_chat(selected_questionnaire, history):\n",
        "    q = df[df['questionnaire'] == selected_questionnaire]['rephrased_question'].tolist()\n",
        "    history.append({\"role\": \"assistant\", \"content\": set_response(q)})\n",
        "    return (\n",
        "        gr.update(visible=False),\n",
        "        gr.update(visible=False),\n",
        "        gr.update(value=history, visible=True),\n",
        "        gr.update(visible=True),\n",
        "        gr.update(visible=True),\n",
        "        gr.State(q)\n",
        "    )\n",
        "\n",
        "\n",
        "def add_message(history, message, unanswered_questions, df_state):\n",
        "    if isinstance(df_state, gr.State):\n",
        "        df_v = df_state.value\n",
        "    else:\n",
        "        df_v = df_state\n",
        "\n",
        "    if len(message[\"files\"]) > 0:\n",
        "        # model_turbo = whisper.load_model(\"turbo\")\n",
        "        # result = model_turbo.transcribe(message[\"files\"][0])\n",
        "        # message = result[\"text\"]\n",
        "        with sr.AudioFile(message[\"files\"][0]) as source:\n",
        "            audio_data = recognizer.record(source)\n",
        "        try:\n",
        "            message = recognizer.recognize_google(audio_data)\n",
        "        except sr.UnknownValueError:\n",
        "            exit(\"Audio could not be understood\")\n",
        "        except sr.RequestError as e:\n",
        "            exit(f\"Error with the request: {e}\")\n",
        "    elif message[\"text\"] is not None and message[\"text\"] != \"\":\n",
        "        message = message[\"text\"]\n",
        "    else:\n",
        "        message = \"<auto> I'm a retailer.\"\n",
        "\n",
        "    history.append({\"role\": \"user\", \"content\": message})\n",
        "    uq_list, df_new = evaluate_message(message, unanswered_questions, df_v)\n",
        "    if len(uq_list) == 0:\n",
        "        return history, gr.update(visible=False), gr.State([]), gr.State(df_new)\n",
        "    else:\n",
        "        return history, gr.MultimodalTextbox(value=None), gr.State(uq_list), gr.State(df_new)\n",
        "\n",
        "\n",
        "def bot(history, unanswered_questions, df_state):\n",
        "    if isinstance(df_state, gr.State):\n",
        "        df_v = df_state.value\n",
        "    else:\n",
        "        df_v = df_state\n",
        "\n",
        "    response = set_response(unanswered_questions, df_v)\n",
        "    history.append({\"role\": \"assistant\", \"content\": \"\"})\n",
        "    for character in response: # Cool writing effect\n",
        "        history[-1][\"content\"] += character\n",
        "        time.sleep(0.007)\n",
        "        yield history\n",
        "\n",
        "\n",
        "def download(selected_questionnaire, df_state):\n",
        "    if isinstance(df_state, gr.State):\n",
        "        df_v = df_state.value\n",
        "    else:\n",
        "        df_v = df_state\n",
        "\n",
        "    current_timestamp = datetime.utcnow()\n",
        "    formatted_timestamp = current_timestamp.strftime(\"%Y%m%d_%H%M%S\")\n",
        "    filename = f\"answers_{formatted_timestamp}.json\"\n",
        "\n",
        "    filtered_df = df_v[df_v['questionnaire'] == selected_questionnaire]\n",
        "    filtered_df = filtered_df[['rephrased_question', 'answer']].rename(columns={\"rephrased_question\": \"question\"})\n",
        "    filtered_df.to_json(filename, orient='records', indent=4)\n",
        "\n",
        "    return filename\n",
        "\n",
        "\n",
        "def reset_state(original_df_state):\n",
        "    return (\n",
        "        gr.update(visible=True),\n",
        "        gr.update(visible=True),\n",
        "        gr.update(value=list(), visible=False),\n",
        "        gr.update(value=dict(), visible=False),\n",
        "        gr.update(visible=False),\n",
        "        gr.State([]),\n",
        "        original_df_state\n",
        "    )"
      ],
      "metadata": {
        "id": "h5L88rxgNgf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_css = \"\"\"\n",
        ".gradio-container {\n",
        "  padding-left: 10% !important;\n",
        "  padding-right: 10% !important;\n",
        "}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "0zWUBoCRRAj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks(theme='Nymbo/Nymbo_Theme', title=\"Philipp's Chatbot\", css=custom_css) as app:\n",
        "    gr.Markdown(\"\"\"\n",
        "        # Questionnaire Chatbot üë®‚ÄçüíªüöÄ\n",
        "        ### by Philipp Landeck\n",
        "        <br>\n",
        "    \"\"\")\n",
        "\n",
        "    unanswered_questions = gr.State(value=[])\n",
        "    df_state = gr.State(value=df)\n",
        "    original_df_state = gr.State(value=df)\n",
        "\n",
        "    dropdown = gr.Dropdown(\n",
        "        choices=list(df['questionnaire'].unique()),\n",
        "        # multiselect=True,\n",
        "        label=\"Choose a questionnaire\",\n",
        "        interactive=True,\n",
        "        visible=True,\n",
        "        value=df['questionnaire'].iloc[0]\n",
        "    )\n",
        "\n",
        "    start_button = gr.Button(\"Start\", visible=True)\n",
        "\n",
        "    chatbot = gr.Chatbot(\n",
        "        show_label=False,\n",
        "        type=\"messages\",\n",
        "        visible=False,\n",
        "        height=500\n",
        "    )\n",
        "\n",
        "    chat_input = gr.MultimodalTextbox(\n",
        "        interactive=True,\n",
        "        sources=['microphone'],\n",
        "        placeholder=\"Enter message or record voice...\",\n",
        "        show_label=False,\n",
        "        autofocus=True,\n",
        "        visible=False\n",
        "    )\n",
        "\n",
        "    # Call download() function\n",
        "    send_button = gr.DownloadButton(\"Send\", value=download, visible=False, inputs=[dropdown, df_state])\n",
        "\n",
        "    # Call start_chat() function\n",
        "    start_button.click(\n",
        "        start_chat, [dropdown, chatbot], [dropdown, start_button, chatbot, chat_input, send_button, unanswered_questions]\n",
        "    )\n",
        "\n",
        "    # Call add_message() function\n",
        "    chat_msg = chat_input.submit(\n",
        "        add_message, [chatbot, chat_input, unanswered_questions, df_state], [chatbot, chat_input, unanswered_questions, df_state]\n",
        "    )\n",
        "\n",
        "    # Call bot() function\n",
        "    chat_msg.then(bot, [chatbot, unanswered_questions, df_state], chatbot)\n",
        "\n",
        "    # Call reset_state() function\n",
        "    send_button.click(\n",
        "        reset_state, [original_df_state], [dropdown, start_button, chatbot, chat_input, send_button, unanswered_questions, df_state]\n",
        "    )"
      ],
      "metadata": {
        "id": "Pb24QzeVADPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start app and generate QR-Code"
      ],
      "metadata": {
        "id": "xSMbhtPCErYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "app.launch(debug=True)"
      ],
      "metadata": {
        "id": "e2sB1xrNHGCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_qr_code(url):\n",
        "    qr = qrcode.QRCode(version=1, box_size=10, border=2)\n",
        "    qr.add_data(url)\n",
        "    qr.make(fit=True)\n",
        "    img = qr.make_image(fill='black', back_color='white')\n",
        "    img_path = 'gradio_code.png'\n",
        "    img.save(img_path)\n",
        "    return img_path"
      ],
      "metadata": {
        "id": "-NKFlacWEqSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Workaround to get the public URL\n",
        "original_stdout = sys.stdout\n",
        "\n",
        "output = io.StringIO()\n",
        "sys.stdout = output # set print to output variable\n",
        "\n",
        "app.launch(share=True, show_api=False, inline=False, favicon_path='/content/favicon.png')\n",
        "\n",
        "sys.stdout = original_stdout # reset print to stdout\n",
        "\n",
        "captured_output = output.getvalue()\n",
        "\n",
        "link_pattern = r'(https://.*\\.gradio\\.live)'\n",
        "re_match = re.search(link_pattern, captured_output)\n",
        "\n",
        "if re_match:\n",
        "    public_url = re_match.group(1)\n",
        "    print(f\"Public URL (click to open the app): {public_url}\\n\")\n",
        "    qr_image_path = generate_qr_code(public_url)\n",
        "    display(Image(qr_image_path))\n",
        "else:\n",
        "    exit(\"No URL found in the captured output.\")"
      ],
      "metadata": {
        "id": "4BJIh5WwIoq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Brainrot Version\n",
        "with gr.Blocks(theme='Nymbo/Nymbo_Theme', title=\"Brainrot Version\") as app:\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            gr.HTML(\"\"\"\n",
        "                <img src=\"https://media1.tenor.com/m/ndmoHqg8xikAAAAd/brian-family-guy.gif\"/>\n",
        "            \"\"\")\n",
        "            gr.HTML(\"\"\"\n",
        "                <img src=\"https://media1.tenor.com/m/I4IrVy2RI64AAAAC/among-us-sus.gif\"/>\n",
        "            \"\"\")\n",
        "        with gr.Column(scale=100):\n",
        "            gr.Markdown(\"\"\"\n",
        "                # Questionnaire Chatbot üë®‚ÄçüíªüöÄ\n",
        "                ### by Philipp Landeck\n",
        "                <br>\n",
        "            \"\"\")\n",
        "\n",
        "            unanswered_questions = gr.State(value=[])\n",
        "            df_state = gr.State(value=df)\n",
        "            original_df_state = gr.State(value=df)\n",
        "\n",
        "            dropdown = gr.Dropdown(\n",
        "                choices=list(df['questionnaire'].unique()),\n",
        "                # multiselect=True,\n",
        "                label=\"Choose a questionnaire\",\n",
        "                interactive=True,\n",
        "                visible=True,\n",
        "                value=df['questionnaire'].iloc[0]\n",
        "            )\n",
        "\n",
        "            start_button = gr.Button(\"Start\", visible=True)\n",
        "\n",
        "            chatbot = gr.Chatbot(\n",
        "                show_label=False,\n",
        "                type=\"messages\",\n",
        "                visible=False,\n",
        "                height=500\n",
        "            )\n",
        "\n",
        "            chat_input = gr.MultimodalTextbox(\n",
        "                interactive=True,\n",
        "                sources=['microphone'],\n",
        "                placeholder=\"Enter message or record voice...\",\n",
        "                show_label=False,\n",
        "                autofocus=True,\n",
        "                visible=False\n",
        "            )\n",
        "\n",
        "            # Call download() function\n",
        "            send_button = gr.DownloadButton(\"Send\", value=download, visible=False, inputs=[dropdown, df_state])\n",
        "\n",
        "            # Call start_chat() function\n",
        "            start_button.click(\n",
        "                start_chat, [dropdown, chatbot], [dropdown, start_button, chatbot, chat_input, send_button, unanswered_questions]\n",
        "            )\n",
        "\n",
        "            # Call add_message() function\n",
        "            chat_msg = chat_input.submit(\n",
        "                add_message, [chatbot, chat_input, unanswered_questions, df_state], [chatbot, chat_input, unanswered_questions, df_state]\n",
        "            )\n",
        "\n",
        "            # Call bot() function\n",
        "            chat_msg.then(bot, [chatbot, unanswered_questions, df_state], chatbot)\n",
        "\n",
        "            # Call reset_state() function\n",
        "            send_button.click(\n",
        "                reset_state, [original_df_state], [dropdown, start_button, chatbot, chat_input, send_button, unanswered_questions, df_state]\n",
        "            )\n",
        "\n",
        "            gr.Image(value=\"brainrot.png\", show_label=False)\n",
        "        with gr.Column(scale=1):\n",
        "            gr.HTML(\"\"\"\n",
        "                <img src=\"https://media1.tenor.com/m/1wZ88hrB5SwAAAAd/subway-surfer.gif\"\n",
        "                style=\"width: 300%;\"/>\n",
        "            \"\"\")\n",
        "\n",
        "app.launch(share=True, show_api=False, inline=False, favicon_path='/content/favicon.png')"
      ],
      "metadata": {
        "id": "99I4gHdaOnEn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}