{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/croco22/CapstoneProjectTDS/blob/philipp/notebooks/Dashboard_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extra Task 3: Live Demo\n",
        "\n",
        "## Imports and Setup"
      ],
      "metadata": {
        "id": "a_5wicdWgEvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install gradio\n",
        "# !pip install git+https://github.com/openai/whisper.git\n",
        "!pip install SpeechRecognition\n",
        "!pip install qrcode[pil]\n",
        "\n",
        "import io\n",
        "import os\n",
        "import logging\n",
        "import sys\n",
        "import time\n",
        "import re\n",
        "import requests\n",
        "from datetime import datetime\n",
        "\n",
        "import pandas as pd\n",
        "import qrcode\n",
        "# import whisper\n",
        "import speech_recognition as sr\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import pipeline\n",
        "import gradio as gr\n",
        "import google.generativeai as genai\n",
        "from IPython.display import display, Image\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "recognizer = sr.Recognizer()\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "\n",
        "# API Setup\n",
        "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "model = genai.GenerativeModel('gemini-2.0-flash-exp')\n",
        "userdata.get('HF_TOKEN')\n",
        "\n",
        "# Download favicon\n",
        "image_url = \"https://raw.githubusercontent.com/croco22/CapstoneProjectTDS/refs/heads/philipp/images/profile.jpg\" # Todo: Set to main branch\n",
        "img_data = requests.get(image_url).content\n",
        "with open('favicon.png', 'wb') as handler:\n",
        "    handler.write(img_data)\n",
        "\n",
        "\n",
        "def generate_text(prompt):\n",
        "    try:\n",
        "        response = model.generate_content(\n",
        "            prompt,\n",
        "            generation_config = genai.GenerationConfig(\n",
        "                temperature=2.0,\n",
        "            )\n",
        "        )\n",
        "        time.sleep(5) # Avoid exceeding API limits\n",
        "        return response.text.strip()\n",
        "    except Exception as e:\n",
        "        exit(\"Error during API call: \", e)"
      ],
      "metadata": {
        "id": "n3aIGKcngDpm"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data from the provided questionnaires"
      ],
      "metadata": {
        "id": "l6lNDb8ERWJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = list()\n",
        "\n",
        "for q in range(1, 6):\n",
        "    url = f'https://raw.githubusercontent.com/croco22/CapstoneProjectTDS/refs/heads/main/questionnaires/questionnaire{q}.json'\n",
        "    temp_df = pd.read_json(url)\n",
        "\n",
        "    # Unpack options into an array\n",
        "    temp_df['options'] = temp_df['options'].apply(lambda x: [option['option'] for option in x])\n",
        "\n",
        "    # Remove options for specific question types\n",
        "    # because irrelevant or do not contribute meaningfully to the dataset\n",
        "    temp_df.loc[temp_df['type'].isin(['TEXT', 'NUMBER', 'DATE']), 'options'] = None\n",
        "\n",
        "    temp_df['questionnaire'] = f\"Questionnaire {q}\"\n",
        "\n",
        "    dfs.append(temp_df)\n",
        "\n",
        "df = pd.concat(dfs, ignore_index=True)"
      ],
      "metadata": {
        "id": "FT5Y15cZQijj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rephrase questions if necessary"
      ],
      "metadata": {
        "id": "7A2T2D-_Ru2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rephrase_question(text):\n",
        "    prompt = f\"\"\"\n",
        "        Reformulate the following statement into a clear, concise, and\n",
        "        grammatically correct question that directly addresses the user. For\n",
        "        example, 'Do you consent to data processing?' or 'What kind of follow-up\n",
        "        would you prefer?'. If the text is already a question, preserve its\n",
        "        meaning and intent without altering the content or facts. The statement\n",
        "        is: '{text}'. Return only the reformulated question, without any\n",
        "        additional explanations, comments, or text.\n",
        "    \"\"\"\n",
        "    return generate_text(prompt)\n",
        "\n",
        "\n",
        "df['rephrased_question'] = df['question'].apply(rephrase_question)\n",
        "\n",
        "df = df[['questionnaire', 'type', 'rephrased_question', 'options']].copy()\n",
        "df['answer'] = \"<skipped by user>\"\n",
        "df['missed_count'] = 0\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "PRffJkreal_J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "636d0f3e-f420-4b90-df36-38d69c30ac1b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     questionnaire           type                          rephrased_question  \\\n",
              "0  Questionnaire 1  SINGLE_SELECT          Do you consent to data processing?   \n",
              "1  Questionnaire 1  SINGLE_SELECT  Which customer group are you referring to?   \n",
              "2  Questionnaire 1   MULTI_SELECT        What products are you interested in?   \n",
              "3  Questionnaire 1   MULTI_SELECT          What kind of follow-up is planned?   \n",
              "4  Questionnaire 1   MULTI_SELECT      Who should be copied in the follow-up?   \n",
              "\n",
              "                                             options             answer  \\\n",
              "0                                          [Yes, No]  <skipped by user>   \n",
              "1  [End User, Wholesaler, Distributor, Consultant...  <skipped by user>   \n",
              "2  [MY-SYSTEM, Notion, JTS, JS EcoLine, AKW100, A...  <skipped by user>   \n",
              "3        [Email, Phone, Schedule a Visit, No action]  <skipped by user>   \n",
              "4  [Stephan Maier, Joachim Wagner, Erik Schneider...  <skipped by user>   \n",
              "\n",
              "   missed_count  \n",
              "0             0  \n",
              "1             0  \n",
              "2             0  \n",
              "3             0  \n",
              "4             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5a8ac1f2-11e6-405c-903e-fec78bc158fd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questionnaire</th>\n",
              "      <th>type</th>\n",
              "      <th>rephrased_question</th>\n",
              "      <th>options</th>\n",
              "      <th>answer</th>\n",
              "      <th>missed_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Questionnaire 1</td>\n",
              "      <td>SINGLE_SELECT</td>\n",
              "      <td>Do you consent to data processing?</td>\n",
              "      <td>[Yes, No]</td>\n",
              "      <td>&lt;skipped by user&gt;</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Questionnaire 1</td>\n",
              "      <td>SINGLE_SELECT</td>\n",
              "      <td>Which customer group are you referring to?</td>\n",
              "      <td>[End User, Wholesaler, Distributor, Consultant...</td>\n",
              "      <td>&lt;skipped by user&gt;</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Questionnaire 1</td>\n",
              "      <td>MULTI_SELECT</td>\n",
              "      <td>What products are you interested in?</td>\n",
              "      <td>[MY-SYSTEM, Notion, JTS, JS EcoLine, AKW100, A...</td>\n",
              "      <td>&lt;skipped by user&gt;</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Questionnaire 1</td>\n",
              "      <td>MULTI_SELECT</td>\n",
              "      <td>What kind of follow-up is planned?</td>\n",
              "      <td>[Email, Phone, Schedule a Visit, No action]</td>\n",
              "      <td>&lt;skipped by user&gt;</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Questionnaire 1</td>\n",
              "      <td>MULTI_SELECT</td>\n",
              "      <td>Who should be copied in the follow-up?</td>\n",
              "      <td>[Stephan Maier, Joachim Wagner, Erik Schneider...</td>\n",
              "      <td>&lt;skipped by user&gt;</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a8ac1f2-11e6-405c-903e-fec78bc158fd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5a8ac1f2-11e6-405c-903e-fec78bc158fd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5a8ac1f2-11e6-405c-903e-fec78bc158fd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5da05af7-55e7-4ff1-a76b-115778ea4521\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5da05af7-55e7-4ff1-a76b-115778ea4521')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5da05af7-55e7-4ff1-a76b-115778ea4521 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 25,\n  \"fields\": [\n    {\n      \"column\": \"questionnaire\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Questionnaire 2\",\n          \"Questionnaire 5\",\n          \"Questionnaire 3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"MULTI_SELECT\",\n          \"NUMBER\",\n          \"TEXT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rephrased_question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          \"What type of company is it?\",\n          \"When do you, the contact person, wish to receive a follow-up?\",\n          \"Do you consent to data processing?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"options\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"<skipped by user>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"missed_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate context\n",
        "The code selects the most relevant question from a list based on a combination of semantic similarity (using embeddings) and contextual relevance (using a question-answering model)."
      ],
      "metadata": {
        "id": "_i48UdQONz7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
        "# embedding_model = SentenceTransformer('all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "FUVvXbGZoxNP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def evaluate_context(context, unanswered_questions):\n",
        "#     best_question = None\n",
        "#     highest_score = -1\n",
        "#     context_embedding = embedding_model.encode([context])\n",
        "\n",
        "#     for question in unanswered_questions:\n",
        "#         qa_result = qa_pipeline(question=question, context=context)\n",
        "#         score = qa_result['score']\n",
        "\n",
        "#         question_embedding = embedding_model.encode([question])\n",
        "#         similarity = cosine_similarity(context_embedding, question_embedding)[0][0]\n",
        "\n",
        "#         combined_score = score * similarity\n",
        "\n",
        "#         if combined_score > highest_score:\n",
        "#             highest_score = combined_score\n",
        "#             best_question = question\n",
        "\n",
        "#     return best_question\n",
        "\n",
        "\n",
        "# # def evaluate_answer(message, options):\n",
        "# #     message_embedding = embedding_model.encode([message])\n",
        "\n",
        "# #     highest_similarity = -1\n",
        "# #     best_answer = None\n",
        "\n",
        "# #     for option in options:\n",
        "# #         option_embedding = embedding_model.encode([option])\n",
        "# #         similarity = cosine_similarity([message_embedding[0]], [option_embedding[0]])[0][0]\n",
        "\n",
        "# #         if similarity > highest_similarity:\n",
        "# #             highest_similarity = similarity\n",
        "# #             best_answer = option\n",
        "\n",
        "# #     return best_answer"
      ],
      "metadata": {
        "id": "DETYkkFVdlvL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "# classifier = pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\")\n",
        "\n",
        "def get_number(text):\n",
        "    prompt = f\"\"\"\n",
        "        Following text contains a phone number: '{text}'.\n",
        "        Extract the phone number and only return the phone number, without any\n",
        "        additional explanations, comments, or text.\n",
        "    \"\"\"\n",
        "    return generate_text(prompt)\n",
        "\n",
        "\n",
        "def get_date(text):\n",
        "    prompt = f\"\"\"\n",
        "        Following text contains a date/time reference: '{text}'.\n",
        "        Extract the date and convert it into the format DD.MM.YYYY. If it\n",
        "        contains a reference like 'in two weeks', take the current date and\n",
        "        return the calculated date based on this. Return the date without any\n",
        "        additional explanations, comments, or text.\n",
        "    \"\"\"\n",
        "    return generate_text(prompt)"
      ],
      "metadata": {
        "id": "3kJgCX3yyzpk",
        "outputId": "ed373e72-4a6f-4e56-a011-07cc99ec60ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1113, in emit\n",
            "    stream.write(msg + self.terminator)\n",
            "ValueError: I/O operation on closed file\n",
            "Call stack:\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n",
            "    lambda f: self._run_callback(functools.partial(callback, future))\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n",
            "    ret = callback()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 825, in inner\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n",
            "    yield gen.maybe_future(dispatch(*args))\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n",
            "    yield gen.maybe_future(handler(stream, idents, msg))\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n",
            "    self.do_execute(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-74-086dabe55152>\", line 1, in <cell line: 0>\n",
            "    classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/pipelines/__init__.py\", line 1178, in pipeline\n",
            "    return pipeline_class(model=model, framework=framework, task=task, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/pipelines/zero_shot_classification.py\", line 89, in __init__\n",
            "    super().__init__(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\", line 916, in __init__\n",
            "    logger.warning(f\"Device set to use {self.device}\")\n",
            "Message: 'Device set to use cpu'\n",
            "Arguments: ()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_context(context, questions, qtype=None):\n",
        "    if qtype is None or qtype == \"SINGLE_SELECT\": # Clustering for qtype=None --> multi_label=True\n",
        "        question_results = classifier(context, candidate_labels=questions)\n",
        "        best_match = question_results[\"labels\"][0]\n",
        "        return best_match\n",
        "    elif qtype == \"MULTI_SELECT\":\n",
        "        question_results = classifier(context, candidate_labels=questions, multi_label=True)\n",
        "        best_matches = [\n",
        "            label for label, score in zip(question_results[\"labels\"], question_results[\"scores\"])\n",
        "            if score > 0.25\n",
        "        ]\n",
        "        return \", \".join(map(str, best_matches))\n",
        "    elif qtype == \"TEXT\":\n",
        "        return context\n",
        "    elif qtype == \"NUMBER\":\n",
        "        return get_number(context)\n",
        "    elif qtype == \"DATE\":\n",
        "        return get_date(context)\n",
        "    else:\n",
        "        return \"[ERROR] Evaluation not possible\""
      ],
      "metadata": {
        "id": "J_FGXapaUI0Z"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradio application"
      ],
      "metadata": {
        "id": "YJ8BIxwGR9Kv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_message(message, unanswered_questions, df_v):\n",
        "    if isinstance(unanswered_questions, gr.State):\n",
        "        uq_list = unanswered_questions.value\n",
        "    else:\n",
        "        uq_list = unanswered_questions\n",
        "\n",
        "    real_question = evaluate_context(message, uq_list)\n",
        "    # for q in real_questions:\n",
        "    answer_options = df_v[df_v['rephrased_question'] == real_question]['options'].iloc[0]\n",
        "    qtype = df_v[df_v['rephrased_question'] == real_question]['type'].iloc[0]\n",
        "    df_v.loc[df_v['rephrased_question'] == real_question, 'answer'] = evaluate_context(message, answer_options, qtype)\n",
        "\n",
        "    real_idx = uq_list.index(real_question)\n",
        "    df_v.loc[(df_v['rephrased_question'].isin(uq_list[:real_idx])), 'missed_count'] += 1\n",
        "\n",
        "    uq_list.remove(real_question)\n",
        "\n",
        "    remaining_uq_list = [question for question in uq_list if df_v[df_v['rephrased_question'] == question]['missed_count'].iloc[0] <= 1]\n",
        "\n",
        "    return remaining_uq_list, df_v\n",
        "\n",
        "\n",
        "def set_response(unanswered_questions, df_v=None):\n",
        "    if isinstance(unanswered_questions, gr.State):\n",
        "        uq_list = unanswered_questions.value\n",
        "    else:\n",
        "        uq_list = unanswered_questions\n",
        "\n",
        "    if len(uq_list) == 0:\n",
        "            return \"Thank you! Please submit your responses via 'Send' :)\"\n",
        "\n",
        "    flag = False\n",
        "    if df_v is None:\n",
        "        unanswered_questions_string = '<ol style=\"font-size: 13px;\">' + ''.join([f'<li>{q}</li>' for q in uq_list]) + '</ol>'\n",
        "        response = f\"\"\"\n",
        "            <p>Please answer the following questions:</p>\n",
        "            <p>{unanswered_questions_string}</p>\n",
        "        \"\"\"\n",
        "    else:\n",
        "        unanswered_questions_string = '<ol style=\"font-size: 13px;\">'\n",
        "        for q in uq_list:\n",
        "            missed_count_row = df_v[df_v['rephrased_question'] == q]\n",
        "            missed_count = missed_count_row['missed_count'].iloc[0]\n",
        "            if missed_count == 1:\n",
        "                flag = True\n",
        "                unanswered_questions_string += f'<li style=\"color: #77f7d1;\">{q}</li>'\n",
        "            else:\n",
        "                unanswered_questions_string += f'<li>{q}</li>'\n",
        "\n",
        "    unanswered_questions_string += '</ol>'\n",
        "    if flag:\n",
        "        response = f\"\"\"\n",
        "            <p>Please answer the following questions<span style='color: #77f7d1;'>*</span>:</p>\n",
        "            <p>{unanswered_questions_string}</p>\n",
        "            <p style='color: #77f7d1; font-size: 10px;'>* Highlighted questions will be skipped if unanswered.</p>\n",
        "        \"\"\"\n",
        "    else:\n",
        "        response = f\"\"\"\n",
        "            <p>Please answer the following questions:</p>\n",
        "            <p>{unanswered_questions_string}</p>\n",
        "        \"\"\"\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "w-YiHZ1gNgLh"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def start_chat(selected_questionnaire, history):\n",
        "    q = df[df['questionnaire'] == selected_questionnaire]['rephrased_question'].tolist()\n",
        "    history.append({\"role\": \"assistant\", \"content\": set_response(q)})\n",
        "    return (\n",
        "        gr.update(visible=False),\n",
        "        gr.update(visible=False),\n",
        "        gr.update(value=history, visible=True),\n",
        "        gr.update(visible=True),\n",
        "        gr.update(visible=True),\n",
        "        gr.State(q)\n",
        "    )\n",
        "\n",
        "\n",
        "def add_message(history, message, unanswered_questions, df_state):\n",
        "    if isinstance(df_state, gr.State):\n",
        "        df_v = df_state.value\n",
        "    else:\n",
        "        df_v = df_state\n",
        "\n",
        "    if len(message[\"files\"]) > 0:\n",
        "        # model_turbo = whisper.load_model(\"turbo\")\n",
        "        # result = model_turbo.transcribe(message[\"files\"][0])\n",
        "        # message = result[\"text\"]\n",
        "        with sr.AudioFile(message[\"files\"][0]) as source:\n",
        "            audio_data = recognizer.record(source)\n",
        "        try:\n",
        "            message = recognizer.recognize_google(audio_data)\n",
        "        except sr.UnknownValueError:\n",
        "            exit(\"Audio could not be understood\")\n",
        "        except sr.RequestError as e:\n",
        "            exit(f\"Error with the request: {e}\")\n",
        "    elif message[\"text\"] is not None and message[\"text\"] != \"\":\n",
        "        message = message[\"text\"]\n",
        "    else:\n",
        "        message = \"<auto> I'm a retailer.\"\n",
        "\n",
        "    history.append({\"role\": \"user\", \"content\": message})\n",
        "    uq_list, df_new = evaluate_message(message, unanswered_questions, df_v) # TODO: EIGENTLICH IN BOT BESSER\n",
        "    if len(uq_list) == 0:\n",
        "        return history, gr.update(visible=False), gr.State([]), gr.State(df_new)\n",
        "    else:\n",
        "        return history, gr.MultimodalTextbox(value=None), gr.State(uq_list), gr.State(df_new)\n",
        "\n",
        "\n",
        "def bot(history, unanswered_questions, df_state):\n",
        "    if isinstance(df_state, gr.State):\n",
        "        df_v = df_state.value\n",
        "    else:\n",
        "        df_v = df_state\n",
        "\n",
        "    response = set_response(unanswered_questions, df_v)\n",
        "    history.append({\"role\": \"assistant\", \"content\": \"\"})\n",
        "    for character in response: # Cool writing effect\n",
        "        history[-1][\"content\"] += character\n",
        "        time.sleep(0.007)\n",
        "        yield history\n",
        "\n",
        "\n",
        "def download(selected_questionnaire, df_state):\n",
        "    if isinstance(df_state, gr.State):\n",
        "        df_v = df_state.value\n",
        "    else:\n",
        "        df_v = df_state\n",
        "\n",
        "    current_timestamp = datetime.now()\n",
        "    formatted_timestamp = current_timestamp.strftime(\"%Y%m%d_%H%M%S\")\n",
        "    filename = f\"answers_{formatted_timestamp}.json\"\n",
        "\n",
        "    filtered_df = df_v[df_v['questionnaire'] == selected_questionnaire]\n",
        "    filtered_df = filtered_df[['rephrased_question', 'answer']].rename(columns={\"rephrased_question\": \"question\"})\n",
        "    filtered_df.to_json(filename, orient='records', indent=4)\n",
        "\n",
        "    return filename\n",
        "\n",
        "\n",
        "def reset_state(original_df_state):\n",
        "    return (\n",
        "        gr.update(visible=True),\n",
        "        gr.update(visible=True),\n",
        "        gr.update(value=list(), visible=False),\n",
        "        gr.update(value=dict(), visible=False),\n",
        "        gr.update(visible=False),\n",
        "        gr.State([]),\n",
        "        original_df_state\n",
        "    )"
      ],
      "metadata": {
        "id": "h5L88rxgNgf7"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_css = \"\"\"\n",
        ".gradio-container {\n",
        "  padding-left: 20% !important;\n",
        "  padding-right: 20% !important;\n",
        "}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "IooN1BJn8HRR"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks(theme='Nymbo/Nymbo_Theme', title=\"Philipp's Chatbot\", css=custom_css) as app:\n",
        "    gr.Markdown(\"\"\"\n",
        "        # Questionnaire Chatbot 👨‍💻🚀\n",
        "        ### by Philipp Landeck\n",
        "        <br>\n",
        "    \"\"\")\n",
        "\n",
        "    unanswered_questions = gr.State(value=[])\n",
        "    df_state = gr.State(value=df)\n",
        "    original_df_state = gr.State(value=df)\n",
        "\n",
        "    dropdown = gr.Dropdown(\n",
        "        choices=list(df['questionnaire'].unique()),\n",
        "        # multiselect=True,\n",
        "        label=\"Choose a questionnaire\",\n",
        "        interactive=True,\n",
        "        visible=True,\n",
        "        value=df['questionnaire'].iloc[0]\n",
        "    )\n",
        "\n",
        "    start_button = gr.Button(\"Start\", visible=True)\n",
        "\n",
        "    chatbot = gr.Chatbot(\n",
        "        show_label=False,\n",
        "        type=\"messages\",\n",
        "        visible=False,\n",
        "        height=500\n",
        "    )\n",
        "\n",
        "    chat_input = gr.MultimodalTextbox(\n",
        "        interactive=True,\n",
        "        sources=['microphone'],\n",
        "        placeholder=\"Enter message or record voice...\",\n",
        "        show_label=False,\n",
        "        autofocus=True,\n",
        "        visible=False\n",
        "    )\n",
        "\n",
        "    # Call download() function\n",
        "    send_button = gr.DownloadButton(\"Send\", value=download, visible=False, inputs=[dropdown, df_state])\n",
        "\n",
        "    # Call start_chat() function\n",
        "    start_button.click(\n",
        "        start_chat, [dropdown, chatbot], [dropdown, start_button, chatbot, chat_input, send_button, unanswered_questions]\n",
        "    )\n",
        "\n",
        "    # Call add_message() function\n",
        "    chat_msg = chat_input.submit(\n",
        "        add_message, [chatbot, chat_input, unanswered_questions, df_state], [chatbot, chat_input, unanswered_questions, df_state]\n",
        "    )\n",
        "\n",
        "    # Call bot() function\n",
        "    chat_msg.then(bot, [chatbot, unanswered_questions, df_state], chatbot)\n",
        "\n",
        "    # Call reset_state() function\n",
        "    send_button.click(\n",
        "        reset_state, [original_df_state], [dropdown, start_button, chatbot, chat_input, send_button, unanswered_questions, df_state]\n",
        "    )"
      ],
      "metadata": {
        "id": "Pb24QzeVADPb"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start app and generate QR-Code"
      ],
      "metadata": {
        "id": "xSMbhtPCErYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_qr_code(url):\n",
        "    qr = qrcode.QRCode(version=1, box_size=10, border=2)\n",
        "    qr.add_data(url)\n",
        "    qr.make(fit=True)\n",
        "    img = qr.make_image(fill='black', back_color='white')\n",
        "    img_path = 'gradio_code.png'\n",
        "    img.save(img_path)\n",
        "    return img_path"
      ],
      "metadata": {
        "id": "-NKFlacWEqSh"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Workaround to get the public URL\n",
        "original_stdout = sys.stdout\n",
        "\n",
        "output = io.StringIO()\n",
        "sys.stdout = output # set print to output variable\n",
        "\n",
        "app.launch(share=True, show_api=False, inline=False, favicon_path='/content/favicon.png')\n",
        "\n",
        "sys.stdout = original_stdout # reset print to stdout\n",
        "\n",
        "captured_output = output.getvalue()\n",
        "\n",
        "link_pattern = r'(https://.*\\.gradio\\.live)'\n",
        "re_match = re.search(link_pattern, captured_output)\n",
        "\n",
        "if re_match:\n",
        "    public_url = re_match.group(1)\n",
        "    print(f\"Public URL (click to open the app): {public_url}\\n\")\n",
        "    qr_image_path = generate_qr_code(public_url)\n",
        "    display(Image(qr_image_path))\n",
        "else:\n",
        "    exit(\"No URL found in the captured output.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "4BJIh5WwIoq_",
        "outputId": "f083766c-6c78-4fe5-e8d7-d9cb03e8fd1b"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL (click to open the app): https://3a99a1fab508f20669.gradio.live\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAFKAQAAAABTUiuoAAACOElEQVR4nO2bTYrjQAyFP3UZeulADtBHqdxgjjRXs4+SAwzYy4YKbxYq/y0GkgFPCka1CIn9LQQPSU8qYuLJM348S0KggQb6AbPVc1se2m3uYLzA8qo7M4BAnz7SlCRJIqtAngBIIvszyZHh7bEG6mjNnrlDA0ka+uK55Zl3Oz2AQP8OHb++zX5ODyPfu3cEEOifz1GQVCxPCOarGL/KPwgg0JfVWmz8wwAw+m+Td7BewHxeAIG+iD7c9wFJMHeQ75+qxtDMzC7NxPp/o2h3piQNJMHysTvhCd+PuoP3r1kF6CVJBXfw9UWo1QSKK+MaLbotWQZ4gsW81QaKNAF5SloGY4C+uIw+fkUlbAR1tTZlyCq1OvoaQwUNfajVBFqFqgnGTjJ/O/Ql+lYz6Nq3ysEdLhlFnqJvtYPWSjj01f/VqrfWxAEit5pBOyAVmLsi5msx6Irl6YrqIh4YL1MLsQbKbrbKh0roRTD6VkvozsHXRrVdcvVltfbRt5pAj7sM7Yau3SIqcqsRdD9b+Yqw3+wgu6QLtRpA15v+9S5rKYdeIrf9bqj1fvS4g4dtwKKuCIFQqxF0TSGoA1Yvd4K1ZU2EJ2wGXeYtwJgvWL53xeBT+NA1p8JoqTQQa6B+029VslQMQOOPX6Z68Z+wrPMCCPRltZbzMI2XhOX7p6gKPixyqxWUzVH4Dv7YxuoJB98Sui3i/acveeduXfKeHUCgz519Mk3UVdM6IldXH56wDdTiH0GBBnoK+huATAL3zgbrJQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}