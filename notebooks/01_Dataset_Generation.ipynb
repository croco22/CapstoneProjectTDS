{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/croco22/CapstoneProjectTDS/blob/main/notebooks/01_Dataset_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1: Dataset Generation\n",
        "This chapter focuses on creating and expanding the dataset. It covers data collection, preprocessing and formatting to ensure compatibility with the model. The goal is to generate high-quality input data that improves model performance.\n",
        "\n",
        "The secret `GOOGLE_API_KEY` must be configured in your Google Colab environment for proper execution.\n",
        "\n",
        "**Remark**: It should be noted that the 503 error encountered when calling the Gemini API is an error on Google's side, typically due to temporary issues such as server overload or maintenance. This can happen when the API service is unable to handle the incoming requests at that moment. For example, a similar issue was reported in the Google AI forum: https://discuss.ai.google.dev/t/error-the-model-is-overloaded/48410"
      ],
      "metadata": {
        "id": "CR5Z-9Uz-6eP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports and Setup"
      ],
      "metadata": {
        "id": "08r_8_xsdHfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "import random\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "from itertools import combinations\n",
        "\n",
        "import pandas as pd\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "# API Setup\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "model = genai.GenerativeModel('gemini-2.0-flash-exp')\n",
        "\n",
        "\n",
        "def generate_text(prompt):\n",
        "    \"\"\"\n",
        "    Generates text based on the provided prompt using the Gemini API. The function sends the prompt\n",
        "    to the model, with a generation configuration that includes a temperature of 2.0 for creative output.\n",
        "    It then waits for 5 seconds to avoid exceeding API limits before returning the generated text.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = model.generate_content(\n",
        "            prompt,\n",
        "            generation_config=genai.GenerationConfig(\n",
        "                temperature=2.0, # creative output\n",
        "            )\n",
        "        )\n",
        "        time.sleep(5) # avoid exceeding API limits\n",
        "        return response.text.strip()\n",
        "    except Exception as e:\n",
        "        exit(\"Error during API call: \", e)"
      ],
      "metadata": {
        "id": "jgaZ4x_pZ2JI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the data from the provided questionnaires"
      ],
      "metadata": {
        "id": "TJ-E8toBbBs4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = list()\n",
        "\n",
        "for q in range(1, 6):\n",
        "    url = f'https://raw.githubusercontent.com/croco22/CapstoneProjectTDS/refs/heads/main/questionnaires/questionnaire{q}.json'\n",
        "    temp_df = pd.read_json(url)\n",
        "\n",
        "    # Unpack options into an array\n",
        "    temp_df['options'] = temp_df['options'].apply(lambda x: [option['option'] for option in x])\n",
        "\n",
        "    # Remove options for specific question types\n",
        "    temp_df.loc[temp_df['type'].isin(['TEXT', 'NUMBER', 'DATE']), 'options'] = None\n",
        "\n",
        "    dfs.append(temp_df)\n",
        "\n",
        "df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "0eim6vrEkxAt",
        "outputId": "635c536b-1759-4109-ee40-37bc229525fc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     id           type  \\\n",
              "0  aa2d8cdd-0758-4035-b0b6-ca18e2f380d8  SINGLE_SELECT   \n",
              "1  12e1ed1d-edaa-4e93-8645-de3850e998f9  SINGLE_SELECT   \n",
              "2  625012ae-9192-4cf6-a73d-55e1813d6014   MULTI_SELECT   \n",
              "3  0699fc5a-34a4-4160-bda1-fb135a3615da   MULTI_SELECT   \n",
              "4  815dab84-bc5e-4764-9777-0c0126e3173e   MULTI_SELECT   \n",
              "\n",
              "                            question  \\\n",
              "0            Data processing consent   \n",
              "1                     Customer group   \n",
              "2             Products interested in   \n",
              "3  What kind of follow up is planned   \n",
              "4           Who to copy in follow up   \n",
              "\n",
              "                                             options  \n",
              "0                                          [Yes, No]  \n",
              "1  [End User, Wholesaler, Distributor, Consultant...  \n",
              "2  [MY-SYSTEM, Notion, JTS, JS EcoLine, AKW100, A...  \n",
              "3        [Email, Phone, Schedule a Visit, No action]  \n",
              "4  [Stephan Maier, Joachim Wagner, Erik Schneider...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a28042bb-46c2-43ad-9c52-904d33bb0dda\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>type</th>\n",
              "      <th>question</th>\n",
              "      <th>options</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aa2d8cdd-0758-4035-b0b6-ca18e2f380d8</td>\n",
              "      <td>SINGLE_SELECT</td>\n",
              "      <td>Data processing consent</td>\n",
              "      <td>[Yes, No]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12e1ed1d-edaa-4e93-8645-de3850e998f9</td>\n",
              "      <td>SINGLE_SELECT</td>\n",
              "      <td>Customer group</td>\n",
              "      <td>[End User, Wholesaler, Distributor, Consultant...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>625012ae-9192-4cf6-a73d-55e1813d6014</td>\n",
              "      <td>MULTI_SELECT</td>\n",
              "      <td>Products interested in</td>\n",
              "      <td>[MY-SYSTEM, Notion, JTS, JS EcoLine, AKW100, A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0699fc5a-34a4-4160-bda1-fb135a3615da</td>\n",
              "      <td>MULTI_SELECT</td>\n",
              "      <td>What kind of follow up is planned</td>\n",
              "      <td>[Email, Phone, Schedule a Visit, No action]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>815dab84-bc5e-4764-9777-0c0126e3173e</td>\n",
              "      <td>MULTI_SELECT</td>\n",
              "      <td>Who to copy in follow up</td>\n",
              "      <td>[Stephan Maier, Joachim Wagner, Erik Schneider...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a28042bb-46c2-43ad-9c52-904d33bb0dda')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a28042bb-46c2-43ad-9c52-904d33bb0dda button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a28042bb-46c2-43ad-9c52-904d33bb0dda');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2117b95a-2573-42d0-9f8d-ed25623e07df\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2117b95a-2573-42d0-9f8d-ed25623e07df')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2117b95a-2573-42d0-9f8d-ed25623e07df button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 25,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"a0148bc7-15b3-41d5-b97c-6420b8bd927c\",\n          \"3dd27f03-db17-4608-8f99-158f5a7c7abf\",\n          \"aa2d8cdd-0758-4035-b0b6-ca18e2f380d8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"MULTI_SELECT\",\n          \"NUMBER\",\n          \"TEXT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"Notes\",\n          \"What phone number can we use for contact?\",\n          \"Data processing consent\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"options\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Additional Questions\n",
        "In this chapter, a set number of new questions is generated for each question type using various prompts. The process leverages the Gemini API 2.0 (experimental), as it provides the best results and fastest performance. This approach ensures a diverse and well-balanced dataset expansion."
      ],
      "metadata": {
        "id": "ilGPysEnn4m_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompts\n",
        "select_question = f\"\"\"\n",
        "    Generate a question that could be asked to an app user in a business\n",
        "    context, designed as either a single-choice or multiple-choice question.\n",
        "    Provide the question and an array of answer options in the format:\n",
        "    [question, [option1, option2, ..., optionN]]\n",
        "    Respond strictly in this format without additional explanations, comments,\n",
        "    or text.\n",
        "\"\"\"\n",
        "\n",
        "text_question = f\"\"\"\n",
        "    Generate a question that could be asked to an app user in a business\n",
        "    context, designed as an open text entry question. Return the generated\n",
        "    question without additional explanations, comments, or text.\n",
        "\"\"\"\n",
        "\n",
        "date_question = f\"\"\"\n",
        "    Generate a question asking an app user in a business context to provide a\n",
        "    date in the future. Return the generated question without additional\n",
        "    explanations, comments, or text.\n",
        "\"\"\"\n",
        "\n",
        "number_question = f\"\"\"\n",
        "    Generate a question asking an app user in a business context to provide a\n",
        "    phone number. Return the generated question without additional\n",
        "    explanations, comments, or text.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "LA8WiauSCtNi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add_data = list()\n",
        "n_questions_per_type = 10\n",
        "\n",
        "for t in df['type'].unique():\n",
        "    for _ in range(n_questions_per_type):\n",
        "        if t == \"SINGLE_SELECT\":\n",
        "            question, options = ast.literal_eval(generate_text(select_question))\n",
        "        elif t == \"MULTI_SELECT\":\n",
        "            question, options = ast.literal_eval(generate_text(select_question))\n",
        "        elif t == \"TEXT\":\n",
        "            question, options = generate_text(text_question), None\n",
        "        elif t == \"DATE\":\n",
        "            question, options = generate_text(date_question), None\n",
        "        elif t == \"NUMBER\":\n",
        "            question, options = generate_text(number_question), None\n",
        "        else:\n",
        "            exit(f\"Unhandled question type: {t}\")\n",
        "\n",
        "        add_data.append({\"type\": t, \"question\": question, \"options\": options})\n",
        "\n",
        "    time.sleep(30)\n",
        "    print(f\"Generated {n_questions_per_type} questions of type: {t}\")\n",
        "\n",
        "add_df = pd.DataFrame(add_data)\n",
        "\n",
        "add_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "jTSZj2kzZU7S",
        "outputId": "07b6a9a6-1b70-47f9-f5eb-e7573a1ded5b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 10 questions of type: SINGLE_SELECT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 556.82ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 557.70ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 531.65ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 506.37ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 10 questions of type: MULTI_SELECT\n",
            "Generated 10 questions of type: TEXT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 532.27ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 10 questions of type: DATE\n",
            "Generated 10 questions of type: NUMBER\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            type                                           question  \\\n",
              "0  SINGLE_SELECT       Which department do you primarily work with?   \n",
              "1  SINGLE_SELECT  What is your primary goal for using this app t...   \n",
              "2  SINGLE_SELECT  What is your primary reason for accessing the ...   \n",
              "3  SINGLE_SELECT  Which of the following areas of our business a...   \n",
              "4  SINGLE_SELECT  What is your primary objective for using this ...   \n",
              "\n",
              "                                             options  \n",
              "0  [Sales, Marketing, Engineering, Customer Suppo...  \n",
              "1  [Submit an expense report, Review project prog...  \n",
              "2  [Review project progress, Update task status, ...  \n",
              "3  [Marketing & Sales, Product Development, Custo...  \n",
              "4  [Generate sales leads, Manage customer interac...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-03b07172-e4db-4052-9a4c-11ed6f701019\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>question</th>\n",
              "      <th>options</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SINGLE_SELECT</td>\n",
              "      <td>Which department do you primarily work with?</td>\n",
              "      <td>[Sales, Marketing, Engineering, Customer Suppo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SINGLE_SELECT</td>\n",
              "      <td>What is your primary goal for using this app t...</td>\n",
              "      <td>[Submit an expense report, Review project prog...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SINGLE_SELECT</td>\n",
              "      <td>What is your primary reason for accessing the ...</td>\n",
              "      <td>[Review project progress, Update task status, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SINGLE_SELECT</td>\n",
              "      <td>Which of the following areas of our business a...</td>\n",
              "      <td>[Marketing &amp; Sales, Product Development, Custo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SINGLE_SELECT</td>\n",
              "      <td>What is your primary objective for using this ...</td>\n",
              "      <td>[Generate sales leads, Manage customer interac...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-03b07172-e4db-4052-9a4c-11ed6f701019')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-03b07172-e4db-4052-9a4c-11ed6f701019 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-03b07172-e4db-4052-9a4c-11ed6f701019');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5c977736-5f0f-430c-9b10-a4fcdaeb5445\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5c977736-5f0f-430c-9b10-a4fcdaeb5445')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5c977736-5f0f-430c-9b10-a4fcdaeb5445 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "add_df",
              "summary": "{\n  \"name\": \"add_df\",\n  \"rows\": 50,\n  \"fields\": [\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"MULTI_SELECT\",\n          \"NUMBER\",\n          \"TEXT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 48,\n        \"samples\": [\n          \"What challenges are you currently facing in your daily workflow?\",\n          \"What is the best phone number to reach you at for business inquiries?\",\n          \"How can we improve your experience using this app for your business needs?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"options\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process Questions\n",
        "This chapter focuses on generating spoken-style answers based on the question type. A distinction is made between different question types, including single-select, multi-select, text, number, and date. Each type is processed using a dedicated handler to ensure appropriate answer generation. The implementation introduces a delay to manage request timing before executing the corresponding function."
      ],
      "metadata": {
        "id": "yvndzq1kaIs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_question(data):\n",
        "    \"\"\"\n",
        "    Generate spoken-style answers for the passed question.\n",
        "    A distinction is made between the different types of questions.\n",
        "    \"\"\"\n",
        "    type_handlers = {\n",
        "        \"SINGLE_SELECT\": handle_single_select,\n",
        "        \"MULTI_SELECT\": handle_multi_select,\n",
        "        \"TEXT\": handle_text,\n",
        "        \"NUMBER\": handle_number,\n",
        "        \"DATE\": handle_date,\n",
        "    }\n",
        "\n",
        "    data_type = data.get('type')\n",
        "    handler = type_handlers.get(data_type)\n",
        "\n",
        "    time.sleep(10)\n",
        "\n",
        "    if handler:\n",
        "        return handler(data)\n",
        "    else:\n",
        "        exit(f\"Unhandled data type: {data_type}\")"
      ],
      "metadata": {
        "id": "DNRhF_GnXzGh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Single-Select"
      ],
      "metadata": {
        "id": "kpYJVGa3EciK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_single_answers(question, option):\n",
        "    prompt = f\"\"\"\n",
        "        You are an app user responding to the following question in a\n",
        "        conversational, spoken style. You enjoy talking, so you respond with\n",
        "        full sentences rather than a simple 'yes' or 'no'.\n",
        "        Question: '{question}'\n",
        "        Your response must explicitly convey the provided content: '{option}'.\n",
        "        Generate 5 unique and varied responses, formatted as:\n",
        "        'answer1§answer2§...§answer5'.\n",
        "        Return only the generated responses in the specified format, without\n",
        "        any additional explanation or comments.\n",
        "        Do not use quotation marks in the response.\n",
        "    \"\"\"\n",
        "    return generate_text(prompt)\n",
        "\n",
        "\n",
        "def handle_single_select(data):\n",
        "    \"\"\"\n",
        "    Example output:\n",
        "    intended_answer: ['Yes', 'Yes', ..., 'No', 'No', ...]\n",
        "    context: ['Yeah, sure thing, ...', 'Nope, I'd rather ...', ...]\n",
        "    \"\"\"\n",
        "    intended_answer = list()\n",
        "    context = list()\n",
        "\n",
        "    for option in data['options']:\n",
        "        response_text = generate_single_answers(data['question'], option)\n",
        "        texts_array = [answer.strip() for answer in response_text.split(\"§\")]\n",
        "\n",
        "        intended_answer.extend([option] * 5)\n",
        "        context.extend(texts_array)\n",
        "\n",
        "    print(f\"Generated context for question: '{data['question']}'\")\n",
        "    return intended_answer, context"
      ],
      "metadata": {
        "id": "l76F8RJuaBQM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-Select"
      ],
      "metadata": {
        "id": "xydEZqimEea3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_multi_answers(question, options):\n",
        "    options_text = \", \".join(options)\n",
        "    prompt = f\"\"\"\n",
        "        You are an app user responding to the following question in a\n",
        "        conversational, spoken style. You enjoy talking, so you respond with\n",
        "        full sentences rather than a simple 'yes' or 'no'.\n",
        "        Question: '{question}'\n",
        "        Your response must contain all of the following text elements\n",
        "        explicitly to be valid: '{options_text}'.\n",
        "        Generate 5 unique and varied responses, formatted as:\n",
        "        'answer1§answer2§...§answer5'.\n",
        "        Return only the generated responses in the specified format, without\n",
        "        any additional explanation or comments.\n",
        "        Do not use quotation marks in the response.\n",
        "    \"\"\"\n",
        "    return generate_text(prompt)\n",
        "\n",
        "\n",
        "def handle_multi_select(data):\n",
        "    \"\"\"\n",
        "    Example output:\n",
        "    intended_answer: [[\"MY-SYSTEM\", \"Notion\"], [\"Notion\"], ...]\n",
        "    context: ['Yeah, that would be MY-SYSTEM and Notion, ...',\n",
        "        'Hmm, I think I'm mainly interested in Notion ...', ...]\n",
        "    \"\"\"\n",
        "    intended_answer = list()\n",
        "    context = list()\n",
        "\n",
        "    # Generate all possible combinations of options (subsets)\n",
        "    all_combinations = list()\n",
        "    for r in range(1, len(data['options']) + 1):\n",
        "        all_combinations.extend(list(combinations(data['options'], r)))\n",
        "\n",
        "    # Shuffle combinations for randomness\n",
        "    random.shuffle(all_combinations)\n",
        "\n",
        "    # Only generate answers for a random sample of combinations\n",
        "    selected_combinations = random.sample(all_combinations, min(5, len(all_combinations)))\n",
        "\n",
        "    for combo in selected_combinations:\n",
        "        response_text = generate_multi_answers(data['question'], combo)\n",
        "        texts_array = [answer.strip() for answer in response_text.split(\"§\")]\n",
        "\n",
        "        intended_answer.extend([combo] * 5)\n",
        "        context.extend(texts_array)\n",
        "\n",
        "    print(f\"Generated context for question: '{data['question']}'\")\n",
        "    return intended_answer, context"
      ],
      "metadata": {
        "id": "g2RIpuQdltm8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text"
      ],
      "metadata": {
        "id": "PGDzZG4JEgjB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xQdppMZmZv4W"
      },
      "outputs": [],
      "source": [
        "def generate_text_answers(question):\n",
        "    prompt = f\"\"\"\n",
        "        You are an app user responding to the following question in a\n",
        "        conversational, spoken style. You enjoy talking, so you respond with\n",
        "        full sentences rather than a simple 'yes' or 'no'.\n",
        "        Question: '{question}'\n",
        "        Generate 5 unique and varied responses, formatted as:\n",
        "        'answer1§answer2§...§answer5'.\n",
        "        Return only the generated responses in the specified format, without\n",
        "        any additional explanation or comments.\n",
        "        Do not use quotation marks in the response.\n",
        "    \"\"\"\n",
        "    return generate_text(prompt)\n",
        "\n",
        "\n",
        "def handle_text(data):\n",
        "    \"\"\"\n",
        "    Example output:\n",
        "    intended_answer: [None, None, ...]\n",
        "    context: ['You can only reach me on ...', 'I have no notes to add.', ...]\n",
        "    \"\"\"\n",
        "    intended_answer = list()\n",
        "    context = list()\n",
        "\n",
        "    response_text = generate_text_answers(data['question'])\n",
        "    texts_array = [answer.strip() for answer in response_text.split(\"§\")]\n",
        "\n",
        "    intended_answer.extend([None] * 5)\n",
        "    context.extend(texts_array)\n",
        "\n",
        "    print(f\"Generated context for question: '{data['question']}'\")\n",
        "    return intended_answer, context"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number"
      ],
      "metadata": {
        "id": "njIon53CEkzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_phone_number():\n",
        "    \"\"\"\n",
        "    Generates a random phone number in an international format.\n",
        "    \"\"\"\n",
        "    country_code = random.choice([\"+1\", \"+44\", \"+49\", \"+33\"])\n",
        "    area_code = random.randint(100, 999)\n",
        "    local_number = f\"{random.randint(100, 999)}-{random.randint(1000, 9999)}\"\n",
        "    return f\"{country_code}-{area_code}-{local_number}\"\n",
        "\n",
        "\n",
        "def generate_number_answers(question, option):\n",
        "    prompt = f\"\"\"\n",
        "        You are an app user responding to the following question in a\n",
        "        conversational, spoken style. You enjoy talking, so you respond with\n",
        "        full sentences rather than a simple 'yes' or 'no'.\n",
        "        Question: '{question}'\n",
        "        Your response must contain the following phone number explicitly\n",
        "        to be valid: '{option}'.\n",
        "        Generate 5 unique and varied responses, formatted as:\n",
        "        'answer1§answer2§...§answer5'.\n",
        "        Return only the generated responses in the specified format, without\n",
        "        any additional explanation or comments.\n",
        "        Do not use quotation marks in the response.\n",
        "    \"\"\"\n",
        "    return generate_text(prompt)\n",
        "\n",
        "\n",
        "def handle_number(data):\n",
        "    \"\"\"\n",
        "    Example output:\n",
        "    intended_answer: ['+44-7700-900123', ...]\n",
        "    context: ['My number is +44-7700-900123.', ...]\n",
        "    \"\"\"\n",
        "    intended_answer = list()\n",
        "    context = list()\n",
        "\n",
        "    phone_numbers = [generate_phone_number() for _ in range(5)]\n",
        "\n",
        "    for option in phone_numbers:\n",
        "        response_text = generate_number_answers(data['question'], option)\n",
        "        texts_array = [answer.strip() for answer in response_text.split(\"§\")]\n",
        "\n",
        "        intended_answer.extend([option] * 5)\n",
        "        context.extend(texts_array)\n",
        "\n",
        "    print(f\"Generated context for question: '{data['question']}'\")\n",
        "    return intended_answer, context"
      ],
      "metadata": {
        "id": "8uyF08h6Em6v"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Date"
      ],
      "metadata": {
        "id": "S3gdjp9sEjZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_date_answers(question):\n",
        "    prompt = f\"\"\"\n",
        "        You are an app user responding to the following question in a\n",
        "        conversational, spoken style. You enjoy talking, so you respond with\n",
        "        full sentences rather than a simple 'yes' or 'no'.\n",
        "        Question: '{question}'\n",
        "        Your answer must contain a time reference in the future, such as\n",
        "        'tomorrow', 'in three weeks', etc.\n",
        "        Build a natural-sounding spoken response around this time reference.\n",
        "        Generate 5 unique and varied responses, each incorporating a different\n",
        "        future time reference, formatted as:\n",
        "        'answer1§answer2§...§answer5§reference1§reference2§...§reference5'.\n",
        "        Return only the generated responses in the specified format, without\n",
        "        any additional explanation or comments.\n",
        "        Do not use quotation marks in the response.\n",
        "    \"\"\"\n",
        "    return generate_text(prompt)\n",
        "\n",
        "\n",
        "def handle_date(data):\n",
        "    \"\"\"\n",
        "    Example output:\n",
        "    intended_answer: ['tomorrow', 'in three weeks', ...]\n",
        "    context: ['Tomorrow would be good ...', 'How about in three weeks ...', ...]\n",
        "    \"\"\"\n",
        "    response_text = generate_date_answers(data['question'])\n",
        "    response_text = response_text.strip('\"').strip(\"'\")\n",
        "    texts_array = [answer.strip() for answer in response_text.split(\"§\")]\n",
        "\n",
        "    intended_answer = texts_array[5:]\n",
        "    context = texts_array[:5]\n",
        "\n",
        "    print(f\"Generated context for question: '{data['question']}'\")\n",
        "    return intended_answer, context"
      ],
      "metadata": {
        "id": "ONp8EhOrEokg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create User Inputs (Context)\n",
        "This section focuses on generating relevant user inputs for each question to provide meaningful context. By incorporating realistic responses, the model can better understand different question types and generate more natural, conversational answers. The context ensures that each question is framed appropriately, improving the quality and coherence of the generated responses."
      ],
      "metadata": {
        "id": "PnwZdR3_oRHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_timestamp():\n",
        "    \"\"\"\n",
        "    Generate random timestamp within the last 30 days.\n",
        "    \"\"\"\n",
        "    start_date = datetime.now() - timedelta(days=30)\n",
        "    random_seconds = random.randint(0, 30 * 24 * 60 * 60)\n",
        "    random_date = start_date + timedelta(seconds=random_seconds)\n",
        "    return random_date\n",
        "\n",
        "\n",
        "df = pd.concat([df, add_df], ignore_index=True)\n",
        "\n",
        "new_cols = ['intended_answer', 'context']\n",
        "\n",
        "df[new_cols] = df.apply(\n",
        "    lambda row: pd.Series(process_question(row)), axis=1\n",
        ")\n",
        "\n",
        "df['timestamp'] = [generate_timestamp() for _ in range(len(df))]\n",
        "\n",
        "df = df.explode(new_cols, ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KRQ-axjMyvTz",
        "outputId": "d5af6b93-939d-4d7b-fa67-b55763a0dbea"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated context for question: 'Data processing consent'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 507.35ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated context for question: 'Customer group'\n",
            "Generated context for question: 'Products interested in'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 506.53ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.16ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated context for question: 'What kind of follow up is planned'\n",
            "Generated context for question: 'Who to copy in follow up'\n",
            "Generated context for question: 'Would you like to receive marketing information from via e-mail?'\n",
            "Generated context for question: 'What industry are you operating in?'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 557.69ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 531.82ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 507.87ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 532.22ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 557.66ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 531.08ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated context for question: 'What products are you interested in?'\n",
            "Generated context for question: 'Notes'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 531.60ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 859.53ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated context for question: 'What type of company is it?'\n",
            "Generated context for question: 'What is the size of your company?'\n",
            "Generated context for question: 'When do you wish to receive a follow-up?'\n",
            "Generated context for question: 'Any additional notes?'\n",
            "Generated context for question: 'Which language is wanted for communication? '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 557.44ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 532.78ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated context for question: 'What is the type of contact?'\n",
            "Generated context for question: 'What is the contact person interested in?'\n",
            "Generated context for question: 'What phone number can we use for contact?'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 532.02ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 557.23ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated context for question: 'When does the contact person wish to receive a follow up?'\n",
            "Generated context for question: 'Customer type'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 531.84ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated context for question: 'Customer satisfaction'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 506.08ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 658.29ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 506.74ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated context for question: 'Size of the trade fair team (on average)'\n",
            "Generated context for question: 'CRM-System'\n",
            "Generated context for question: 'Productinterests'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 506.72ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 759.81ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated context for question: 'Searches a solution for'\n",
            "Generated context for question: 'Next steps'\n",
            "Generated context for question: 'Which department do you primarily work with?'\n",
            "Generated context for question: 'What is your primary goal for using this app today?'\n",
            "Generated context for question: 'What is your primary reason for accessing the project dashboard today?'\n",
            "Generated context for question: 'Which of the following areas of our business are you most interested in learning about?'\n",
            "Generated context for question: 'What is your primary objective for using this platform today?'\n",
            "Generated context for question: 'Which of the following best describes your primary goal for using this app today?'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 633.39ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated context for question: 'What is the primary goal of your meeting today?'\n",
            "Generated context for question: 'Which of these tasks would improve your efficiency today?'\n",
            "Generated context for question: 'Which of the following areas would you like to see improved in our project management process?'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 507.73ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 505.97ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated context for question: 'Which of the following best describes your primary work responsibility?'\n",
            "Generated context for question: 'What is your primary reason for using our project management tool today?'\n",
            "Generated context for question: 'What is your primary role in your current project?'\n",
            "Generated context for question: 'What is your primary goal for using this reporting feature today?'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 531.56ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 532.03ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated context for question: 'What is your primary goal for using this application today?'\n",
            "Generated context for question: 'Which department do you primarily work within?'\n",
            "Generated context for question: 'What is your primary reason for accessing the CRM today?'\n",
            "Generated context for question: 'Which of the following best describes your primary reason for using our expense tracking app this week?'\n",
            "Generated context for question: 'Which department are you primarily working with this week?'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 531.68ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 531.87ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 556.89ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated context for question: 'What is your primary reason for using this expense reporting app?'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 508.19ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated context for question: 'Which of these areas would benefit most from additional investment?'\n",
            "Generated context for question: 'How could we improve your experience using this app for your business?'\n",
            "Generated context for question: 'What are some areas where you believe our product could better meet your business needs?'\n",
            "Generated context for question: 'How can our services be improved to better meet your needs?'\n",
            "Generated context for question: 'What are the primary challenges you currently face in managing your team's workload?'\n",
            "Generated context for question: 'What are your biggest challenges in managing your current projects?'\n",
            "Generated context for question: 'What are the biggest challenges you're currently facing in managing your projects?'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 533.07ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 532.70ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated context for question: 'How can we improve your experience using this app for your business needs?'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 632.88ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 531.70ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated context for question: 'What challenges are you currently facing in your daily workflow?'\n",
            "Generated context for question: 'Describe how our service has impacted your business operations.'\n",
            "Generated context for question: 'Describe the most significant challenge your team is currently facing.'\n",
            "Generated context for question: 'What is the desired completion date for this project?'\n",
            "Generated context for question: 'What is the projected completion date?'\n",
            "Generated context for question: 'When would you like this task to be completed by?'\n",
            "Generated context for question: 'What date in the future would you like to schedule this?'\n",
            "Generated context for question: 'What is the expected completion date?'\n",
            "Generated context for question: 'What is the anticipated completion date?'\n",
            "Generated context for question: 'What date would you like to schedule this for?'\n",
            "Generated context for question: 'What is the anticipated completion date?'\n",
            "Generated context for question: 'When would you like this to be completed?'\n",
            "Generated context for question: 'When would you like this to be completed?'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 556.53ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 531.47ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 556.89ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated context for question: 'Could you please provide your phone number for verification and to facilitate direct communication regarding your account?'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1164.97ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated context for question: 'To ensure seamless communication, what's the best phone number to reach you?'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 531.02ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated context for question: 'What is the best phone number to reach you at for business inquiries?'\n",
            "Generated context for question: 'Could you please provide your phone number so we can contact you if needed?'\n",
            "Generated context for question: 'What is the best phone number to reach you at for business purposes?'\n",
            "Generated context for question: 'Could you please provide your phone number so we can reach you regarding your business inquiry?'\n",
            "Generated context for question: 'Could you please provide your phone number for verification?'\n",
            "Generated context for question: 'What phone number can we use to contact you regarding this business inquiry?'\n",
            "Generated context for question: 'To better assist you, what is your business phone number?'\n",
            "Generated context for question: 'To best reach you, could you please provide your phone number?'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of unique questions:\", df['question'].nunique())\n",
        "print(\"Number Q&A-pairs (= number of rows in dataset):\", len(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qx2zRv1eM5qm",
        "outputId": "23be03dc-a247-4a53-cd73-a9e252b3e768"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique questions: 73\n",
            "Number Q&A-pairs (= number of rows in dataset): 1430\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save dataset to a new JSON file\n",
        "df.to_json('qa_dataset.json', orient='records', indent=4)"
      ],
      "metadata": {
        "id": "13UftBzMo1nk"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}