{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOucyuNEs7pneB8DF+7vKyd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/croco22/CapstoneProjectTDS/blob/seb/Generate_Flie%C3%9Ftext_Daten.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extra Task: Continous Text generation"
      ],
      "metadata": {
        "id": "EZL0IsGRBxUP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kuWe-GQV-66K",
        "outputId": "8b8129fb-0f51-4a08-f93f-686af6645392"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting word2number\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: word2number\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5568 sha256=5e27579b51818cad1ec2142485e0ac7c11829e780c0a647e4a83aaa7b981a1de\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/ef/ae/073b491b14d25e2efafcffca9e16b2ee6d114ec5c643ba4f06\n",
            "Successfully built word2number\n",
            "Installing collected packages: word2number\n",
            "Successfully installed word2number-1.1\n",
            "Retrieved file: qa_dataset.json\n"
          ]
        }
      ],
      "source": [
        "!pip install word2number\n",
        "\n",
        "import json\n",
        "import time\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import requests\n",
        "from word2number import w2n\n",
        "import re\n",
        "import random  # Random-Modul importieren\n",
        "\n",
        "# API setup\n",
        "key = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=key)\n",
        "ai_model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "\n",
        "# Read dataset file\n",
        "url = 'https://raw.githubusercontent.com/croco22/CapstoneProjectTDS/refs/heads/main/qa_dataset.json'\n",
        "response = requests.get(url)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    data = response.json()\n",
        "    print(\"Retrieved file: qa_dataset.json\")\n",
        "else:\n",
        "    print(\"Error while parsing a file: \", response.status_code)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Neues Datenset generieren\n",
        "def generate_dataset(data):\n",
        "    new_dataset = []\n",
        "\n",
        "    # Fragen mischen\n",
        "    random.shuffle(data)\n",
        "\n",
        "    # Gruppiere die Daten in Dreiergruppen\n",
        "    for i in range(0, len(data), 3):\n",
        "        group = data[i:i+3]\n",
        "\n",
        "        # Fließtext generieren\n",
        "        text_parts = []\n",
        "        questions = []\n",
        "\n",
        "        for entry in group:\n",
        "            question = entry[\"question\"]\n",
        "            answer = entry[\"intended_answer\"]\n",
        "            context = entry[\"context\"]\n",
        "\n",
        "            text_parts.append(f\"{context}\")\n",
        "            questions.append({\n",
        "                \"question\": question,\n",
        "                \"intended_answer\": answer\n",
        "            })\n",
        "\n",
        "        # Den Fließtext zusammenfügen\n",
        "        text = \" \".join(text_parts)\n",
        "\n",
        "        # Eintrag in das neue Dataset hinzufügen\n",
        "        new_dataset.append({\n",
        "            \"text\": text,\n",
        "            \"questions\": questions\n",
        "        })\n",
        "\n",
        "    return new_dataset\n",
        "\n",
        "# Speichern des neuen Datensets\n",
        "def save_dataset(data, output_path):\n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "# Hauptfunktion zum Ausführen\n",
        "def main():\n",
        "    output_file = \"new_qa_dataset.json\"  # Neuer Dateipfad\n",
        "\n",
        "    # Neues Datenset generieren\n",
        "    new_dataset = generate_dataset(data)\n",
        "\n",
        "    # Neues Datenset speichern\n",
        "    save_dataset(new_dataset, output_file)\n",
        "    print(f\"Das neue Dataset wurde in {output_file} gespeichert.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIAsdQJKCow3",
        "outputId": "3201871e-c5f8-4516-bf9d-54ca6511b65c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Das neue Dataset wurde in new_qa_dataset.json gespeichert.\n"
          ]
        }
      ]
    }
  ]
}